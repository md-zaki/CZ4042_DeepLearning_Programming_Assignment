{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>melspectrogram_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184.570312</td>\n",
       "      <td>623</td>\n",
       "      <td>69.222222</td>\n",
       "      <td>0.515281</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.443441</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.669799</td>\n",
       "      <td>63.340282</td>\n",
       "      <td>1.811605</td>\n",
       "      <td>58.117188</td>\n",
       "      <td>-3.286546</td>\n",
       "      <td>54.268448</td>\n",
       "      <td>-2.719069</td>\n",
       "      <td>59.548176</td>\n",
       "      <td>-4.559987</td>\n",
       "      <td>70.774803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.999081</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "      <td>0.487201</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.542182</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.274423</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.204988</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.666375</td>\n",
       "      <td>90.256195</td>\n",
       "      <td>1.573594</td>\n",
       "      <td>105.070496</td>\n",
       "      <td>-0.742024</td>\n",
       "      <td>82.417496</td>\n",
       "      <td>-1.961745</td>\n",
       "      <td>119.312355</td>\n",
       "      <td>1.513660</td>\n",
       "      <td>101.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112.347147</td>\n",
       "      <td>1614</td>\n",
       "      <td>146.727273</td>\n",
       "      <td>0.444244</td>\n",
       "      <td>0.099268</td>\n",
       "      <td>0.442014</td>\n",
       "      <td>0.083224</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.013410</td>\n",
       "      <td>0.218063</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.502390</td>\n",
       "      <td>73.079750</td>\n",
       "      <td>0.202623</td>\n",
       "      <td>72.040550</td>\n",
       "      <td>-4.021009</td>\n",
       "      <td>73.844353</td>\n",
       "      <td>-5.916223</td>\n",
       "      <td>103.834824</td>\n",
       "      <td>-2.939086</td>\n",
       "      <td>113.598824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>2060</td>\n",
       "      <td>158.461538</td>\n",
       "      <td>0.454156</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.257672</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>0.214154</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.812989</td>\n",
       "      <td>93.791893</td>\n",
       "      <td>-0.429413</td>\n",
       "      <td>60.002579</td>\n",
       "      <td>-4.013513</td>\n",
       "      <td>82.544540</td>\n",
       "      <td>-5.858006</td>\n",
       "      <td>84.402092</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>90.126389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.999540</td>\n",
       "      <td>66</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.478780</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.414859</td>\n",
       "      <td>0.089313</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>0.128487</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.584204</td>\n",
       "      <td>64.973305</td>\n",
       "      <td>0.744403</td>\n",
       "      <td>68.908516</td>\n",
       "      <td>-6.354805</td>\n",
       "      <td>66.414391</td>\n",
       "      <td>-6.555534</td>\n",
       "      <td>47.852840</td>\n",
       "      <td>-4.809713</td>\n",
       "      <td>73.033966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12052</th>\n",
       "      <td>86.132812</td>\n",
       "      <td>1605</td>\n",
       "      <td>160.500000</td>\n",
       "      <td>0.549566</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>0.438854</td>\n",
       "      <td>0.078327</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.779257</td>\n",
       "      <td>67.892044</td>\n",
       "      <td>3.546391</td>\n",
       "      <td>49.891026</td>\n",
       "      <td>-3.597707</td>\n",
       "      <td>70.953079</td>\n",
       "      <td>-2.672421</td>\n",
       "      <td>62.369473</td>\n",
       "      <td>-3.812236</td>\n",
       "      <td>47.410625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12053</th>\n",
       "      <td>184.570312</td>\n",
       "      <td>3037</td>\n",
       "      <td>168.722222</td>\n",
       "      <td>0.584372</td>\n",
       "      <td>0.074350</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.078894</td>\n",
       "      <td>0.258216</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.979423</td>\n",
       "      <td>63.430107</td>\n",
       "      <td>3.869859</td>\n",
       "      <td>52.517521</td>\n",
       "      <td>-1.637068</td>\n",
       "      <td>59.811417</td>\n",
       "      <td>-3.041467</td>\n",
       "      <td>55.640205</td>\n",
       "      <td>-5.101839</td>\n",
       "      <td>43.080894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12054</th>\n",
       "      <td>143.554688</td>\n",
       "      <td>1549</td>\n",
       "      <td>129.083333</td>\n",
       "      <td>0.541845</td>\n",
       "      <td>0.088258</td>\n",
       "      <td>0.441677</td>\n",
       "      <td>0.080670</td>\n",
       "      <td>0.261484</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.238145</td>\n",
       "      <td>79.961853</td>\n",
       "      <td>3.689087</td>\n",
       "      <td>68.597672</td>\n",
       "      <td>-1.665412</td>\n",
       "      <td>70.761398</td>\n",
       "      <td>0.218386</td>\n",
       "      <td>86.220604</td>\n",
       "      <td>-4.678007</td>\n",
       "      <td>85.629585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12055</th>\n",
       "      <td>143.554688</td>\n",
       "      <td>8820</td>\n",
       "      <td>284.516129</td>\n",
       "      <td>0.532886</td>\n",
       "      <td>0.089102</td>\n",
       "      <td>0.469113</td>\n",
       "      <td>0.077342</td>\n",
       "      <td>0.265298</td>\n",
       "      <td>0.012950</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.302938</td>\n",
       "      <td>80.636742</td>\n",
       "      <td>2.619849</td>\n",
       "      <td>63.592182</td>\n",
       "      <td>-0.559597</td>\n",
       "      <td>62.905022</td>\n",
       "      <td>0.256377</td>\n",
       "      <td>56.687534</td>\n",
       "      <td>-3.086725</td>\n",
       "      <td>62.594326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12056</th>\n",
       "      <td>161.499023</td>\n",
       "      <td>11617</td>\n",
       "      <td>305.710526</td>\n",
       "      <td>0.542927</td>\n",
       "      <td>0.086831</td>\n",
       "      <td>0.453742</td>\n",
       "      <td>0.079466</td>\n",
       "      <td>0.257759</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.718580</td>\n",
       "      <td>72.062149</td>\n",
       "      <td>2.075150</td>\n",
       "      <td>64.020851</td>\n",
       "      <td>-2.384962</td>\n",
       "      <td>62.014175</td>\n",
       "      <td>-1.276020</td>\n",
       "      <td>55.155994</td>\n",
       "      <td>-4.978727</td>\n",
       "      <td>51.976971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12057 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
       "0      184.570312          623      69.222222          0.515281   \n",
       "1      151.999081          521      74.428571          0.487201   \n",
       "2      112.347147         1614     146.727273          0.444244   \n",
       "3      107.666016         2060     158.461538          0.454156   \n",
       "4       75.999540           66      33.000000          0.478780   \n",
       "...           ...          ...            ...               ...   \n",
       "12052   86.132812         1605     160.500000          0.549566   \n",
       "12053  184.570312         3037     168.722222          0.584372   \n",
       "12054  143.554688         1549     129.083333          0.541845   \n",
       "12055  143.554688         8820     284.516129          0.532886   \n",
       "12056  161.499023        11617     305.710526          0.542927   \n",
       "\n",
       "       chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
       "0             0.093347        0.443441       0.082742          0.249143   \n",
       "1             0.094461        0.542182       0.073359          0.274423   \n",
       "2             0.099268        0.442014       0.083224          0.264430   \n",
       "3             0.100834        0.424370       0.084435          0.257672   \n",
       "4             0.100000        0.414859       0.089313          0.252143   \n",
       "...                ...             ...            ...               ...   \n",
       "12052         0.078633        0.438854       0.078327          0.258500   \n",
       "12053         0.074350        0.478900       0.078894          0.258216   \n",
       "12054         0.088258        0.441677       0.080670          0.261484   \n",
       "12055         0.089102        0.469113       0.077342          0.265298   \n",
       "12056         0.086831        0.453742       0.079466          0.257759   \n",
       "\n",
       "       chroma_cens_var  melspectrogram_mean  ...  mfcc15_mean  mfcc15_var  \\\n",
       "0             0.021261             0.038422  ...   -10.669799   63.340282   \n",
       "1             0.008025             0.204988  ...    -5.666375   90.256195   \n",
       "2             0.013410             0.218063  ...    -5.502390   73.079750   \n",
       "3             0.016938             0.214154  ...    -8.812989   93.791893   \n",
       "4             0.019757             0.128487  ...    -6.584204   64.973305   \n",
       "...                ...                  ...  ...          ...         ...   \n",
       "12052         0.016511             0.008974  ...   -12.779257   67.892044   \n",
       "12053         0.016658             0.006628  ...    -9.979423   63.430107   \n",
       "12054         0.014959             0.008848  ...   -11.238145   79.961853   \n",
       "12055         0.012950             0.009798  ...   -10.302938   80.636742   \n",
       "12056         0.016893             0.011106  ...   -10.718580   72.062149   \n",
       "\n",
       "       mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  \\\n",
       "0         1.811605   58.117188    -3.286546   54.268448    -2.719069   \n",
       "1         1.573594  105.070496    -0.742024   82.417496    -1.961745   \n",
       "2         0.202623   72.040550    -4.021009   73.844353    -5.916223   \n",
       "3        -0.429413   60.002579    -4.013513   82.544540    -5.858006   \n",
       "4         0.744403   68.908516    -6.354805   66.414391    -6.555534   \n",
       "...            ...         ...          ...         ...          ...   \n",
       "12052     3.546391   49.891026    -3.597707   70.953079    -2.672421   \n",
       "12053     3.869859   52.517521    -1.637068   59.811417    -3.041467   \n",
       "12054     3.689087   68.597672    -1.665412   70.761398     0.218386   \n",
       "12055     2.619849   63.592182    -0.559597   62.905022     0.256377   \n",
       "12056     2.075150   64.020851    -2.384962   62.014175    -1.276020   \n",
       "\n",
       "       mfcc18_var  mfcc19_mean  mfcc19_var  \n",
       "0       59.548176    -4.559987   70.774803  \n",
       "1      119.312355     1.513660  101.014572  \n",
       "2      103.834824    -2.939086  113.598824  \n",
       "3       84.402092     0.686969   90.126389  \n",
       "4       47.852840    -4.809713   73.033966  \n",
       "...           ...          ...         ...  \n",
       "12052   62.369473    -3.812236   47.410625  \n",
       "12053   55.640205    -5.101839   43.080894  \n",
       "12054   86.220604    -4.678007   85.629585  \n",
       "12055   56.687534    -3.086725   62.594326  \n",
       "12056   55.155994    -4.978727   51.976971  \n",
       "\n",
       "[12057 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP\n",
    "from common_utils import CustomDataset\n",
    "from common_utils import loss_fn\n",
    "from common_utils import split_dataset, preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "X_train = df.drop(['filename', 'label'], axis=1)\n",
    "y_train = df['label'].to_numpy()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = {}, {}, {}, {}\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "        for train_idx, test_idx in cv.split(X_train, y_train):\n",
    "            x_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            \n",
    "            x_test_fold, y_test_fold = X_train[test_idx], y_train[test_idx]\n",
    "\n",
    "            x_train_fold_scale, x_test_fold_scale = preprocess_dataset(x_train_fold, x_test_fold)\n",
    "            \n",
    "            X_train_scaled_dict[batch_size].append(x_train_fold_scale)\n",
    "            X_val_scaled_dict[batch_size].append(x_test_fold_scale)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_test_fold)\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Size: 128\n",
      "Done!\n",
      "fold 0:0.6564400221116639\n",
      "Done!\n",
      "fold 1:0.7763266998341625\n",
      "Done!\n",
      "fold 2:0.7873289091663211\n",
      "Done!\n",
      "fold 3:0.8049564496059726\n",
      "Done!\n",
      "fold 4:0.8219618415595189\n",
      "\n",
      "Batch Size: 256\n",
      "Done!\n",
      "fold 0:0.6394254219100576\n",
      "Done!\n",
      "fold 1:0.7445066334991708\n",
      "Done!\n",
      "fold 2:0.7505184570717546\n",
      "Done!\n",
      "fold 3:0.7817295727913729\n",
      "Done!\n",
      "fold 4:0.7971795935296557\n",
      "\n",
      "Batch Size: 512\n",
      "Done!\n",
      "fold 0:0.6466324292515916\n",
      "Done!\n",
      "fold 1:0.7757048092868988\n",
      "Done!\n",
      "fold 2:0.7855661551223558\n",
      "Done!\n",
      "fold 3:0.8022604728328495\n",
      "Done!\n",
      "fold 4:0.8130236416424719\n",
      "\n",
      "Batch Size: 1024\n",
      "Done!\n",
      "fold 0:0.6252533628155518\n",
      "Done!\n",
      "fold 1:0.7338308457711442\n",
      "Done!\n",
      "fold 2:0.7388753925460686\n",
      "Done!\n",
      "fold 3:0.7745748652011613\n",
      "Done!\n",
      "fold 4:0.7870593114890088\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from datetime import datetime\n",
    "no_epochs = 100\n",
    "from common_utils import EarlyStopper\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter):\n",
    "    cross_validation_accuracies, cross_validation_times = [], []\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "    for batch_size in batch_sizes:\n",
    "        print()\n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        \n",
    "        model = MLP(77,128,2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        fold_acc = []\n",
    "        for fold in range(5):\n",
    "            train_data = CustomDataset(X_train_scaled_dict[batch_size][fold], y_train_dict[batch_size][fold])\n",
    "            test_data = CustomDataset(X_val_scaled_dict[batch_size][fold], y_val_dict[batch_size][fold])\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "            epoch_acc = []\n",
    "            for epoch in range(no_epochs):\n",
    "                start_time = datetime.now()\n",
    "                for batch, (x_train,y_train) in enumerate(train_dataloader):\n",
    "                    pred = model(x_train)\n",
    "                    loss = loss_fn(pred, y_train)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                \n",
    "                size = len(test_dataloader.dataset)\n",
    "                correct = 0\n",
    "                test_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch,(x_test, y_test) in enumerate(test_dataloader):\n",
    "                        pred = model(x_test)\n",
    "                        test_loss += loss_fn(pred,y_test).item()\n",
    "                        correct += (pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
    "\n",
    "                test_loss /= size\n",
    "                acc = correct/size\n",
    "                epoch_acc.append(acc)\n",
    "                end_time = datetime.now()\n",
    "                elapsed_time = end_time - start_time\n",
    "                if early_stopper.early_stop(test_loss):\n",
    "                    print(\"Done!\")\n",
    "                    if(fold == 4):\n",
    "                        cross_validation_times.append(elapsed_time.microseconds/1000000)\n",
    "                    break\n",
    "                if epoch == no_epochs-1 and fold == 4:\n",
    "                    cross_validation_times.append(elapsed_time.microseconds/1000000)\n",
    "\n",
    "            avg_epoch_acc = np.mean(np.array(epoch_acc), axis = 0)\n",
    "            print(\"fold \" + str(fold) + \":\" + str(avg_epoch_acc))\n",
    "            fold_acc.append(avg_epoch_acc)\n",
    "        cross_validation_accuracies.append(np.mean(np.array(fold_acc), axis = 0))\n",
    "\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "        \n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cross-validation accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAKnCAYAAAB58PepAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQA0lEQVR4nO3de1xVVf7/8fc5IBeJgwICYnjJu+WlvJBjYzpSUFqpjWFpGpHVjJeUsmT6ilrfGbSLkWVfupBao6NjWU01kYjm5IhSmmOWkpccvACiJigWKGf//ujnmc4AykHYR46v5+OxH8NZe621P1uH4O3ee22LYRiGAAAAAAANyuruAgAAAADgckD4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMIG3uwtorOx2uw4fPqzAwEBZLBZ3lwMAAADATQzD0MmTJxUZGSmrtebrW4SvOjp8+LCioqLcXQYAAACAS8SBAwd05ZVX1rif8FVHgYGBkn7+A7bZbG6uBgAAAIC7lJaWKioqypERakL4qqNztxrabDbCFwAAAIALPo7EghsAAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJLonwtXDhQrVt21Z+fn6Kjo5Wbm5ujX0HDRoki8VSZRs6dKijT3X7LRaLnn32WUef48ePa8yYMbLZbGrWrJkSExN16tSpBj1PAAAAAJcvt4evFStWKCkpSbNmzdLWrVvVs2dPxcbG6siRI9X2X7VqlQoKChzbjh075OXlpVGjRjn6/HJ/QUGB3nzzTVksFt15552OPmPGjNE333yjrKwsffTRR/rHP/6hBx98sMHPFwAAAMDlyWIYhuHOAqKjo9W3b1+9/PLLkiS73a6oqChNnjxZM2bMuOD4tLQ0paSkqKCgQAEBAdX2GT58uE6ePKns7GxJ0s6dO9WtWzd98cUX6tOnjyQpMzNTt956qw4ePKjIyMgLHre0tFRBQUEqKSmRzWar7ekCAAAA8DC1zQZuvfJVUVGhLVu2KCYmxtFmtVoVExOjnJycWs2RkZGh0aNH1xi8ioqK9PHHHysxMdHRlpOTo2bNmjmClyTFxMTIarVq8+bN1c5TXl6u0tJSpw0AAAAAasut4evo0aOqrKxUeHi4U3t4eLgKCwsvOD43N1c7duzQAw88UGOfJUuWKDAwUCNHjnS0FRYWKiwszKmft7e3goODazxuamqqgoKCHFtUVNQF6wMAAACAc9z+zNfFyMjIUPfu3dWvX78a+7z55psaM2aM/Pz8LupYycnJKikpcWwHDhy4qPkAAAAAXF683Xnw0NBQeXl5qaioyKm9qKhIERER5x1bVlam5cuX66mnnqqxz+eff668vDytWLHCqT0iIqLKgh5nz57V8ePHazyur6+vfH19z1sTAAAAANTErVe+fHx81Lt3b8dCGNLPC25kZ2erf//+5x27cuVKlZeXa+zYsTX2ycjIUO/evdWzZ0+n9v79++vEiRPasmWLo23t2rWy2+2Kjo6u49kAAAAAQM3cftthUlKSXn/9dS1ZskQ7d+7U7373O5WVlSkhIUGSNG7cOCUnJ1cZl5GRoeHDhyskJKTaeUtLS7Vy5cpqnwfr2rWr4uLiNGHCBOXm5uqf//ynJk2apNGjR9dqpUMAAAAAcJVbbzuUpPj4eBUXFyslJUWFhYXq1auXMjMzHYtw5Ofny2p1zoh5eXnasGGDVq9eXeO8y5cvl2EYuvvuu6vdv3TpUk2aNElDhgyR1WrVnXfeqQULFtTfiTWwF7K+k5fVoilDOlbZtyB7tyrthqbd1MkNlQEAAACojtvf89VYufs9Xwuyd2t+1ndKuqmTUwCrqR0AAABAw6htNnD7lS/UzblgNT/rO8dnghcAAABw6SJ8NWK/DGAvr92jiko7wQsAAAC4RLl9wQ1cnClDOsrHy6qKSrt8vKwELwAAAOASRfhq5BZk73YEr4pKuxZk73Z3SQAAAACqwW2Hjdh/P+N17rMkroABAAAAlxjCVyNV3eIa1S3CAQAAAODSQPhqpCrtRrWLa5z7XGnnDQIAAADApYT3fNWRu9/zBQAAAODSUNtswIIbAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJnB7+Fq4cKHatm0rPz8/RUdHKzc3t8a+gwYNksViqbINHTrUqd/OnTt1++23KygoSAEBAerbt6/y8/PPO8/DDz/cYOcIAAAAAN7uPPiKFSuUlJSk9PR0RUdHKy0tTbGxscrLy1NYWFiV/qtWrVJFRYXj87Fjx9SzZ0+NGjXK0bZ3717dcMMNSkxM1Jw5c2Sz2fTNN9/Iz8/Paa4JEyboqaeecnxu2rRpA5whAAAAAPzMYhiG4a6DR0dHq2/fvnr55ZclSXa7XVFRUZo8ebJmzJhxwfFpaWlKSUlRQUGBAgICJEmjR49WkyZN9Pbbb9c4btCgQerVq5fS0tLqXHtpaamCgoJUUlIim81W53kAAAAANG61zQZuu+2woqJCW7ZsUUxMzH+KsVoVExOjnJycWs2RkZGh0aNHO4KX3W7Xxx9/rE6dOik2NlZhYWGKjo7W+++/X2Xs0qVLFRoaqmuuuUbJyck6ffr0eY9VXl6u0tJSpw0AAAAAastt4evo0aOqrKxUeHi4U3t4eLgKCwsvOD43N1c7duzQAw884Gg7cuSITp06pblz5youLk6rV6/WiBEjNHLkSK1fv97R75577tGf//xnrVu3TsnJyXr77bc1duzY8x4vNTVVQUFBji0qKsrFMwYAAABwOXPrM18XIyMjQ927d1e/fv0cbXa7XZJ0xx13aNq0aZKkXr16aePGjUpPT9eNN94oSXrwwQcdY7p3766WLVtqyJAh2rt3r9q3b1/t8ZKTk5WUlOT4XFpaSgADAAAAUGtuu/IVGhoqLy8vFRUVObUXFRUpIiLivGPLysq0fPlyJSYmVpnT29tb3bp1c2rv2rWr02qH/y06OlqStGfPnhr7+Pr6ymazOW0AgNp7Ies7LcjeXe2+Bdm79ULWdyZXBACAudwWvnx8fNS7d29lZ2c72ux2u7Kzs9W/f//zjl25cqXKy8ur3Cro4+Ojvn37Ki8vz6n9u+++U5s2bWqcb9u2bZKkli1bungWAIDa8rJaNL+aALYge7fmZ30nL6vFTZUBAGAOt952mJSUpPHjx6tPnz7q16+f0tLSVFZWpoSEBEnSuHHj1KpVK6WmpjqNy8jI0PDhwxUSElJlzunTpys+Pl4DBw7U4MGDlZmZqQ8//FCfffaZpJ+Xol+2bJluvfVWhYSEaPv27Zo2bZoGDhyoHj16NPg5A8DlasqQjpKk+f//CteUIR0dwSvppk6O/QAAeCq3hq/4+HgVFxcrJSVFhYWF6tWrlzIzMx2LcOTn58tqdb44l5eXpw0bNmj16tXVzjlixAilp6crNTVVU6ZMUefOnfXuu+/qhhtukPTz1bE1a9Y4gl5UVJTuvPNO/c///E/DniwAwCmAvbx2jyoq7QQvAMBlw63v+WrMeM8XANRdpyc/UUWlXT5eVn33x1vcXQ4AABflkn/PFwDg8rQge7cjeFVU2mtchAMAAE/TaJeaBwA0Pv/9jNe5z5K49RAA4PEIXwAAU1S3uEZ1i3AAAOCpCF8AAFNU2o1qF9c497nSziPIAADPxoIbdcSCGwAAAAAkFtwAAAAAgEsK4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABO4PXwtXLhQbdu2lZ+fn6Kjo5Wbm1tj30GDBslisVTZhg4d6tRv586duv322xUUFKSAgAD17dtX+fn5jv0//fSTJk6cqJCQEF1xxRW68847VVRU1GDnCAAAAABuDV8rVqxQUlKSZs2apa1bt6pnz56KjY3VkSNHqu2/atUqFRQUOLYdO3bIy8tLo0aNcvTZu3evbrjhBnXp0kWfffaZtm/frpkzZ8rPz8/RZ9q0afrwww+1cuVKrV+/XocPH9bIkSMb/HwBAAAAXL4shmEY7jp4dHS0+vbtq5dfflmSZLfbFRUVpcmTJ2vGjBkXHJ+WlqaUlBQVFBQoICBAkjR69Gg1adJEb7/9drVjSkpK1KJFCy1btky//e1vJUm7du1S165dlZOTo+uvv75WtZeWliooKEglJSWy2Wy1GgMAAADA89Q2G7jtyldFRYW2bNmimJiY/xRjtSomJkY5OTm1miMjI0OjR492BC+73a6PP/5YnTp1UmxsrMLCwhQdHa3333/fMWbLli06c+aM03G7dOmi1q1bn/e45eXlKi0tddoAAAAAoLbcFr6OHj2qyspKhYeHO7WHh4ersLDwguNzc3O1Y8cOPfDAA462I0eO6NSpU5o7d67i4uK0evVqjRgxQiNHjtT69eslSYWFhfLx8VGzZs1cOm5qaqqCgoIcW1RUlAtnCwAAAOBy5/YFN+oqIyND3bt3V79+/RxtdrtdknTHHXdo2rRp6tWrl2bMmKFhw4YpPT39oo6XnJyskpISx3bgwIGLmg8AAADA5cVt4Ss0NFReXl5VVhksKipSRETEeceWlZVp+fLlSkxMrDKnt7e3unXr5tTetWtXx2qHERERqqio0IkTJ1w6rq+vr2w2m9MGAAAAALXltvDl4+Oj3r17Kzs729Fmt9uVnZ2t/v37n3fsypUrVV5errFjx1aZs2/fvsrLy3Nq/+6779SmTRtJUu/evdWkSROn4+bl5Sk/P/+CxwUAAACAuvJ258GTkpI0fvx49enTR/369VNaWprKysqUkJAgSRo3bpxatWql1NRUp3EZGRkaPny4QkJCqsw5ffp0xcfHa+DAgRo8eLAyMzP14Ycf6rPPPpMkBQUFKTExUUlJSQoODpbNZtPkyZPVv3//Wq90CAAAAACucmv4io+PV3FxsVJSUlRYWKhevXopMzPTsQhHfn6+rFbni3N5eXnasGGDVq9eXe2cI0aMUHp6ulJTUzVlyhR17txZ7777rm644QZHnxdeeEFWq1V33nmnysvLFRsbq1deeaXhThQAAADAZc+t7/lqzHjPFwAAAACpEbznCwAAAAAuJ4QvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMIHL4evGG2/UW2+9pR9//LEh6gEAAAAAj+Ry+Lr22mv12GOPKSIiQhMmTNCmTZsaoi4AAAAA8Cguh6+0tDQdPnxYixYt0pEjRzRw4EB169ZNzz33nIqKihqiRgAAAABo9Or0zJe3t7dGjhypDz74QAcPHtQ999yjmTNnKioqSsOHD9fatWvru04AAAAAaNQuasGN3NxczZo1S88//7zCwsKUnJys0NBQDRs2TI899lh91QgAAAAAjZ7FMAzDlQFHjhzR22+/rUWLFmn37t267bbb9MADDyg2NlYWi0WStGHDBsXFxenUqVMNUvSloLS0VEFBQSopKZHNZnN3OQAAAADcpLbZwNvVia+88kq1b99e999/v+677z61aNGiSp8ePXqob9++rk4NAAAAAB7L5fCVnZ2tX//61+ftY7PZtG7dujoXBQAAAACexuVnvq688krt3r27Svvu3bu1f//++qgJAAAAADyOy+Hrvvvu08aNG6u0b968Wffdd1991AQAAAAAHsfl8PXVV19pwIABVdqvv/56bdu2rT5qAgAAAACP43L4slgsOnnyZJX2kpISVVZW1ktRAAAAAOBpXA5fAwcOVGpqqlPQqqysVGpqqm644YZ6LQ4AAAAAPIXLqx3OmzdPAwcOVOfOnR2rHn7++ecqLS3V2rVr671AAAAAAPAELl/56tatm7Zv36677rpLR44c0cmTJzVu3Djt2rVL11xzTUPUCAAAAACNnsUwDMPdRTRGtX2LNQAAAADPVtts4PJth+ecPn1a+fn5qqiocGrv0aNHXacEAAAAAI/lcvgqLi5WQkKCPvnkk2r3s+IhAAAAAFTl8jNfU6dO1YkTJ7R582b5+/srMzNTS5YsUceOHfW3v/2tTkUsXLhQbdu2lZ+fn6Kjo5Wbm1tj30GDBslisVTZhg4d6uhz3333VdkfFxfnNE/btm2r9Jk7d26d6gcAAACAC3H5ytfatWv1wQcfqE+fPrJarWrTpo1uuukm2Ww2paamOoWg2lixYoWSkpKUnp6u6OhopaWlKTY2Vnl5eQoLC6vSf9WqVU63Oh47dkw9e/bUqFGjnPrFxcVp0aJFjs++vr5V5nrqqac0YcIEx+fAwECXagcAAACA2nL5yldZWZkjFDVv3lzFxcWSpO7du2vr1q0uFzB//nxNmDBBCQkJ6tatm9LT09W0aVO9+eab1fYPDg5WRESEY8vKylLTpk2rhC9fX1+nfs2bN68yV2BgoFOfgIAAl+sHAAAAgNpwOXx17txZeXl5kqSePXvq1Vdf1aFDh5Senq6WLVu6NFdFRYW2bNmimJiY/xRktSomJkY5OTm1miMjI0OjR4+uEpw+++wzhYWFqXPnzvrd736nY8eOVRk7d+5chYSE6Nprr9Wzzz6rs2fP1nic8vJylZaWOm0AAAAAUFsu33b4yCOPqKCgQJI0a9YsxcXFaenSpfLx8dHixYtdmuvo0aOqrKxUeHi4U3t4eLh27dp1wfG5ubnasWOHMjIynNrj4uI0cuRItWvXTnv37tUf/vAH3XLLLcrJyZGXl5ckacqUKbruuusUHBysjRs3Kjk5WQUFBZo/f361x0pNTdWcOXNcOj8AAAAAOOei3/N1+vRp7dq1S61bt1ZoaKhLYw8fPqxWrVpp48aN6t+/v6P98ccf1/r167V58+bzjn/ooYeUk5Oj7du3n7ffvn371L59e61Zs0ZDhgypts+bb76phx56SKdOnar2+bDy8nKVl5c7PpeWlioqKor3fAEAAACXudq+58ul2w7PnDmj9u3ba+fOnY62pk2b6rrrrnM5eElSaGiovLy8VFRU5NReVFSkiIiI844tKyvT8uXLlZiYeMHjXHXVVQoNDdWePXtq7BMdHa2zZ89q//791e739fWVzWZz2gAAAACgtlwKX02aNNFPP/1Ubwf38fFR7969lZ2d7Wiz2+3Kzs52uhJWnZUrV6q8vFxjx4694HEOHjyoY8eOnfeZtG3btslqtVa7wiIAAAAAXCyXF9yYOHGi5s2bd97FKVyRlJSk119/XUuWLNHOnTv1u9/9TmVlZUpISJAkjRs3TsnJyVXGZWRkaPjw4QoJCXFqP3XqlKZPn65NmzZp//79ys7O1h133KEOHTooNjZWkpSTk6O0tDT961//0r59+7R06VJNmzZNY8eOrXZVRAAAAAC4WC4vuPHFF18oOztbq1evVvfu3ausMrhq1SqX5ouPj1dxcbFSUlJUWFioXr16KTMz07EIR35+vqxW54yYl5enDRs2aPXq1VXm8/Ly0vbt27VkyRKdOHFCkZGRuvnmm/X00087nuXy9fXV8uXLNXv2bJWXl6tdu3aaNm2akpKSXKodAAAAAGrL5QU3zl2RqskvX2zsyWr7UB0AAAAAz1bbbODyla/LJVwBAAAAQH1y+ZkvAAAAAIDrXL7y1a5dO1kslhr379u376IKAgAAAABP5HL4mjp1qtPnM2fO6KuvvlJmZqamT59eX3UBAAAAgEdxOXw98sgj1bYvXLhQX3755UUXBAAAAACeqN6e+brlllv07rvv1td0AAAAAOBR6i18vfPOOwoODq6v6QAAAADAo7h82+G1117rtOCGYRgqLCxUcXGxXnnllXotDgAAAAA8hcvha/jw4U6frVarWrRooUGDBqlLly71VRcAAAAAeBSLYRiGu4tojGr7FmsAAAAAnq222cDlZ77+/ve/69NPP63S/umnn+qTTz5xdToAAAAAuCy4HL5mzJihysrKKu2GYWjGjBn1UhQAAAAAeBqXw9fu3bvVrVu3Ku1dunTRnj176qUoAAAAAPA0LoevoKAg7du3r0r7nj17FBAQUC9FAQAAAICncTl83XHHHZo6dar27t3raNuzZ48effRR3X777fVaHAAAAAB4CpfD1zPPPKOAgAB16dJF7dq1U7t27dS1a1eFhIToueeea4gaAQAAAKDRc/k9X0FBQdq4caOysrL0r3/9S/7+/urRo4cGDhzYEPUBAAAAgEfgPV91xHu+AAAAAEgN+J6vKVOmaMGCBVXaX375ZU2dOtXV6QAAAADgsuBy+Hr33Xc1YMCAKu2/+tWv9M4779RLUQAAAADgaVwOX8eOHVNQUFCVdpvNpqNHj9ZLUQAAAADgaVwOXx06dFBmZmaV9k8++URXXXVVvRQFAAAAAJ7G5dUOk5KSNGnSJBUXF+s3v/mNJCk7O1vPP/+80tLS6rs+AAAAAPAILoev+++/X+Xl5frjH/+op59+WpLUtm1b/d///Z/GjRtX7wUCAAAAgCe4qKXmi4uL5e/vryuuuKI+a2oUWGoeAAAAgFT7bODyla9fatGixcUMBwAAAIDLRp3C1zvvvKO//vWvys/PV0VFhdO+rVu31kthAAAAAOBJXF7tcMGCBUpISFB4eLi++uor9evXTyEhIdq3b59uueWWhqgRAAAAABo9l8PXK6+8otdee00vvfSSfHx89PjjjysrK0tTpkxRSUlJQ9QIAAAAAI2ey+ErPz9fv/rVryRJ/v7+OnnypCTp3nvv1V/+8pf6rQ4AAAAAPITL4SsiIkLHjx+XJLVu3VqbNm2SJH3//fe6iIUTAQAAAMCjuRy+fvOb3+hvf/ubJCkhIUHTpk3TTTfdpPj4eI0YMaLeCwQAAAAAT+Dye77sdrvsdru8vX9eKHH58uXauHGjOnbsqIceekg+Pj4NUuilhvd8AQAAAJBqnw0u6iXLlzPCFwAAAACp9tnA5dsOAQAAAACuI3wBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJnA5fBUVFenee+9VZGSkvL295eXl5bQBAAAAAKrydnXAfffdp/z8fM2cOVMtW7aUxWJpiLoAAAAAwKO4HL42bNigzz//XL169WqAcgAAAADAM7l822FUVJR4LzMAAAAAuMbl8JWWlqYZM2Zo//79DVAOAAAAAHgml287jI+P1+nTp9W+fXs1bdpUTZo0cdp//PjxeisOAAAAADyFy+ErLS2tAcoAAAAAAM/mcvgaP358Q9QBAAAAAB7N5fAlSZWVlXr//fe1c+dOSdLVV1+t22+/nfd8AQAAAEANXA5fe/bs0a233qpDhw6pc+fOkqTU1FRFRUXp448/Vvv27eu9SAAAAABo7Fxe7XDKlClq3769Dhw4oK1bt2rr1q3Kz89Xu3btNGXKlIaoEQAAAAAaPZevfK1fv16bNm1ScHCwoy0kJERz587VgAED6rU4AAAAAPAULl/58vX11cmTJ6u0nzp1Sj4+PvVSFAAAAAB4GpfD17Bhw/Tggw9q8+bNMgxDhmFo06ZNevjhh3X77bc3RI0AAAAA0Oi5HL4WLFig9u3bq3///vLz85Ofn58GDBigDh066MUXX2yIGgEAAACg0XP5ma9mzZrpgw8+0O7du7Vr1y5JUteuXdWhQ4d6Lw4AAAAAPEWd3vMlSR07dlTHjh3rsxYAAAAA8Fi1Cl9JSUl6+umnFRAQoKSkpPP2nT9/fr0UBgAAAACepFbh66uvvtKZM2ccXwMAAAAAXGMxDMNwdxGNUWlpqYKCglRSUiKbzebucgAAAAC4SW2zgcurHd5///3VvuerrKxM999/v6vTAQAAAMBlweXwtWTJEv34449V2n/88Ue99dZb9VIUAAAAAHiaWq92WFpa6nip8smTJ+Xn5+fYV1lZqb///e8KCwtrkCIBAAAAoLGrdfhq1qyZLBaLLBaLOnXqVGW/xWLRnDlz6rU4AAAAAPAUtb7tcN26dcrOzpZhGHrnnXe0du1ax7Zhwwbl5+frySefrFMRCxcuVNu2beXn56fo6Gjl5ubW2HfQoEGOEPjLbejQoY4+9913X5X9cXFxTvMcP35cY8aMkc1mU7NmzZSYmKhTp07VqX4AAAAAuJBaX/m68cYbJUnff/+9oqKiZLW6/LhYtVasWKGkpCSlp6crOjpaaWlpio2NVV5eXrW3Ma5atUoVFRWOz8eOHVPPnj01atQop35xcXFatGiR47Ovr6/T/jFjxqigoEBZWVk6c+aMEhIS9OCDD2rZsmX1cl4AAAAA8Et1Xmr+9OnTys/PdwpCktSjRw+X5omOjlbfvn318ssvS5LsdruioqI0efJkzZgx44Lj09LSlJKSooKCAgUEBEj6+crXiRMn9P7771c7ZufOnerWrZu++OIL9enTR5KUmZmpW2+9VQcPHlRkZOQFj8tS8wAAAACkBlxqvri4WMOGDVNgYKCuvvpqXXvttU6bKyoqKrRlyxbFxMT8pyCrVTExMcrJyanVHBkZGRo9erQjeJ3z2WefKSwsTJ07d9bvfvc7HTt2zLEvJydHzZo1cwQvSYqJiZHVatXmzZtdOgcAAAAAqA2Xw9fUqVN14sQJbd68Wf7+/srMzNSSJUvUsWNH/e1vf3NprqNHj6qyslLh4eFO7eHh4SosLLzg+NzcXO3YsUMPPPCAU3tcXJzeeustZWdna968eVq/fr1uueUWVVZWSpIKCwur3NLo7e2t4ODgGo9bXl6u0tJSpw0AAAAAaqvWz3yds3btWn3wwQfq06ePrFar2rRpo5tuukk2m02pqalOC180tIyMDHXv3l39+vVzah89erTj6+7du6tHjx5q3769PvvsMw0ZMqROx0pNTWU1RwAAAAB15vKVr7KyMsdVo+bNm6u4uFjSzyFn69atLs0VGhoqLy8vFRUVObUXFRUpIiLignUsX75ciYmJFzzOVVddpdDQUO3Zs0eSFBERoSNHjjj1OXv2rI4fP17jcZOTk1VSUuLYDhw4cMHjAgAAAMA5Loevzp07Ky8vT5LUs2dPvfrqqzp06JDS09PVsmVLl+by8fFR7969lZ2d7Wiz2+3Kzs5W//79zzt25cqVKi8v19ixYy94nIMHD+rYsWOO+vr3768TJ05oy5Ytjj5r166V3W5XdHR0tXP4+vrKZrM5bQAAAABQWy7fdvjII4+ooKBAkjRr1izFxcVp6dKl8vHx0eLFi10uICkpSePHj1efPn3Ur18/paWlqaysTAkJCZKkcePGqVWrVkpNTXUal5GRoeHDhyskJMSp/dSpU5ozZ47uvPNORUREaO/evXr88cfVoUMHxcbGSpK6du2quLg4TZgwQenp6Tpz5owmTZqk0aNH12qlQwAAAABwlcvh65dXmnr37q1///vf2rVrl1q3bq3Q0FCXC4iPj1dxcbFSUlJUWFioXr16KTMz07EIR35+fpV3iuXl5WnDhg1avXp1lfm8vLy0fft2LVmyRCdOnFBkZKRuvvlmPf30007v+lq6dKkmTZqkIUOGyGq16s4779SCBQtcrh8AAAAAaqPO7/m63PGeLwAAAABS7bNBra58JSUl1frA8+fPr3VfAAAAALhc1Cp8ffXVV06ft27dqrNnz6pz586SpO+++05eXl7q3bt3/VcIAAAAAB6gVuFr3bp1jq/nz5+vwMBALVmyRM2bN5ck/fDDD0pISNCvf/3rhqkSAAAAABo5l5/5atWqlVavXq2rr77aqX3Hjh26+eabdfjw4Xot8FLFM18AAAAApNpnA5ff81VaWup4sfIvFRcX6+TJk65OBwAAAACXBZfD14gRI5SQkKBVq1bp4MGDOnjwoN59910lJiZq5MiRDVEjAAAAADR6Lr/nKz09XY899pjuuecenTlz5udJvL2VmJioZ599tt4LBAAAAABPUOf3fJWVlWnv3r2SpPbt2ysgIKBeC7vU8cwXAAAAAKme3/NVnYCAAPXo0aOuwwEAAADgslKr8DVy5EgtXrxYNpvtgs91rVq1ql4KAwAAAABPUqvwFRQUJIvF4vgaAAAAAOCaOj/zdbnjmS8AAAAAUgO+5wsAAAAA4Lpa3XZ47bXXOm47vJCtW7deVEEAAAAA4IlqFb6GDx/ewGUAAAAAgGfjma864pkvAAAAABLPfAEAAADAJcXllyxXVlbqhRde0F//+lfl5+eroqLCaf/x48frrTgAAAAA8BQuX/maM2eO5s+fr/j4eJWUlCgpKUkjR46U1WrV7NmzG6BEAAAAAGj8XA5fS5cu1euvv65HH31U3t7euvvuu/XGG28oJSVFmzZtaogaAQAAAKDRczl8FRYWqnv37pKkK664QiUlJZKkYcOG6eOPP67f6gAAAADAQ7gcvq688koVFBRIktq3b6/Vq1dLkr744gv5+vrWb3UAAAAA4CFcDl8jRoxQdna2JGny5MmaOXOmOnbsqHHjxun++++v9wIBAAAAwBNc9Hu+Nm3apI0bN6pjx4667bbb6quuSx7v+QIAAAAg1T4buLzU/E8//SQ/Pz/H5+uvv17XX3993aoEAAAAgMuEy7cdhoWFafz48crKypLdbm+ImgAAAADA47gcvpYsWaLTp0/rjjvuUKtWrTR16lR9+eWXDVEbAAAAAHiMOi24sXLlShUVFelPf/qTvv32W11//fXq1KmTnnrqqYaoEQAAAAAavYtecEOSvv32W40ZM0bbt29XZWVlfdR1yWPBDQAAAABS7bOBy1e+zvnpp5/017/+VcOHD9d1112n48ePa/r06XWdDgAAAAA8msurHX766adatmyZ3n//fXl7e+u3v/2tVq9erYEDBzZEfQAAAADgEVwOXyNGjNCwYcP01ltv6dZbb1WTJk0aoi4AAAAA8Cguh6+ioiIFBgZKkg4ePKjIyEhZrXW+exEAAAAALgsup6ZzwUuSunXrpv3799dnPQAAAADgkS7qklU9LJQIAAAAAJcF7hcEAAAAABNcVPj6wx/+oODg4PqqBQAAAAA81kWFr+TkZAUGBmrbtm364Ycf6qsmAAAAAPA4LoevqVOnKiMjQ5JUWVmpG2+8Udddd52ioqL02Wef1Xd9AAAAAOARXA5f77zzjnr27ClJ+vDDD7Vv3z7t2rVL06ZN05NPPlnvBQIAAACAJ3A5fB09elQRERGSpL///e+666671KlTJ91///36+uuv671AAAAAAPAELoev8PBwffvtt6qsrFRmZqZuuukmSdLp06fl5eVV7wUCAAAAgCfwdnVAQkKC7rrrLrVs2VIWi0UxMTGSpM2bN6tLly71XiAAAAAAeAKXw9fs2bN1zTXX6MCBAxo1apR8fX0lSV5eXpoxY0a9FwgAAAAAnsBiGIZxsZOcOHFCzZo1q4dyGo/S0lIFBQWppKRENpvN3eUAAAAAcJPaZgOXn/maN2+eVqxY4fh81113KSQkRFdeeaW2b99et2oBAAAAwMO5HL7S09MVFRUlScrKylJWVpY++eQTxcXF6bHHHqv3AgEAAADAE7j8zFdhYaEjfH300Ue66667dPPNN6tt27aKjo6u9wIBAAAAwBO4fOWrefPmOnDggCQpMzPTsdqhYRiqrKys3+oAAAAAwEO4fOVr5MiRuueee9SxY0cdO3ZMt9xyiyTpq6++UocOHeq9QAAAAADwBC6HrxdeeEFt27bVgQMH9Mwzz+iKK66QJBUUFOj3v/99vRcIAAAAAJ6gXpaavxyx1DwAAAAAqfbZwOUrX5K0d+9epaWlaefOnZKkbt26aerUqbrqqqvqVi0AAAAAeDiXF9z49NNP1a1bN+Xm5qpHjx7q0aOHNm/erG7duikrK6shagQAAACARs/l2w6vvfZaxcbGau7cuU7tM2bM0OrVq7V169Z6LfBSxW2HAAAAAKTaZwOXr3zt3LlTiYmJVdrvv/9+ffvtt65OBwAAAACXBZfDV4sWLbRt27Yq7du2bVNYWFh91AQAAAAAHsflBTcmTJigBx98UPv27dOvfvUrSdI///lPzZs3T0lJSfVeIAAAAAB4Apef+TIMQ2lpaXr++ed1+PBhSVJkZKSmT5+uKVOmyGKxNEihlxqe+QIAAAAgNdBS82fPntWyZct0zz33aNq0aTp58qQkKTAw8OKqBQAAAAAP59IzX97e3nr44Yf1008/Sfo5dBG8AAAAAODCXF5wo1+/fvrqq68aohYAAAAA8FguL7jx+9//Xo8++qgOHjyo3r17KyAgwGl/jx496q04AAAAAPAULi+4YbVWvVhmsVhkGIYsFosqKyvrrbhLGQtuAAAAAJAa8CXL33//fZVt3759jv+ti4ULF6pt27by8/NTdHS0cnNza+w7aNAgWSyWKtvQoUOr7f/www/LYrEoLS3Nqb1t27ZV5pg7d26d6gcAAACAC3H5tsM2bdrUawErVqxQUlKS0tPTFR0drbS0NMXGxiovL6/alzavWrVKFRUVjs/Hjh1Tz549NWrUqCp933vvPW3atEmRkZHVHvupp57ShAkTHJ9ZPAQAAABAQ3H5yldqaqrefPPNKu1vvvmm5s2b53IB8+fP14QJE5SQkKBu3bopPT1dTZs2rfYYkhQcHKyIiAjHlpWVpaZNm1YJX4cOHdLkyZO1dOlSNWnSpNq5AgMDneb67+fXAAAAAKC+uBy+Xn31VXXp0qVK+9VXX6309HSX5qqoqNCWLVsUExPzn4KsVsXExCgnJ6dWc2RkZGj06NFOwclut+vee+/V9OnTdfXVV9c4du7cuQoJCdG1116rZ599VmfPnq2xb3l5uUpLS502AAAAAKgtl287LCwsVMuWLau0t2jRQgUFBS7NdfToUVVWVio8PNypPTw8XLt27brg+NzcXO3YsUMZGRlO7fPmzZO3t7emTJlS49gpU6bouuuuU3BwsDZu3Kjk5GQVFBRo/vz51fZPTU3VnDlzanFWAAAAAFCVy+ErKipK//znP9WuXTun9n/+8581PlvVUDIyMtS9e3f169fP0bZlyxa9+OKL2rp1qywWS41jk5KSHF/36NFDPj4+euihh5SamipfX98q/ZOTk53GlJaWKioqqp7OBAAAAICnczl8TZgwQVOnTtWZM2f0m9/8RpKUnZ2txx9/XI8++qhLc4WGhsrLy0tFRUVO7UVFRYqIiDjv2LKyMi1fvlxPPfWUU/vnn3+uI0eOqHXr1o62yspKPfroo0pLS9P+/furnS86Olpnz57V/v371blz5yr7fX19qw1lAAAAAFAbLoev6dOn69ixY/r973/vWHXQz89PTzzxhJKTk12ay8fHR71791Z2draGDx8u6efntbKzszVp0qTzjl25cqXKy8s1duxYp/Z7773X6RkySYqNjdW9996rhISEGufbtm2brFZrtSssAgAAAMDFcjl8WSwWzZs3TzNnztTOnTvl7++vjh071vmqUFJSksaPH68+ffqoX79+SktLU1lZmSMojRs3Tq1atVJqaqrTuIyMDA0fPlwhISFO7SEhIVXamjRpooiICMcVrZycHG3evFmDBw9WYGCgcnJyNG3aNI0dO1bNmzev03kAAAAAwPm4HL7OueKKK9S3b9+LLiA+Pl7FxcVKSUlRYWGhevXqpczMTMciHPn5+bJanRdlzMvL04YNG7R69eo6HdPX11fLly/X7NmzVV5ernbt2mnatGlOz3QBAAAAQH2yGIZhuLuIxqi0tFRBQUEqKSmRzWZzdzkAAAAA3KS22cDl93wBAAAAAFxH+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELqCcvZH2nBdm7q923IHu3Xsj6zuSKAAAAcCkhfAH1xMtq0fxqAtiC7N2an/WdvKwWN1UGAACAS4G3uwsAPMWUIR0lSfP//xWuKUM6OoJX0k2dHPsBAABweSJ8AfXolwHs5bV7VFFpJ3gBAABAErcdAvVuypCO8vGyqqLSLh8vK8ELAAAAkghfQL1bkL3bEbwqKu01LsIBAACAywu3HQL16L+f8Tr3WRJXwAAAAC5zhC+gnlS3uEZ1i3AAAADg8kT4AupJpd2odnGNc58r7YY7ygIAAMAlwmIYBr8R1kFpaamCgoJUUlIim83m7nIAAAAAuEltswELbgAAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABggksifC1cuFBt27aVn5+foqOjlZubW2PfQYMGyWKxVNmGDh1abf+HH35YFotFaWlpTu3Hjx/XmDFjZLPZ1KxZMyUmJurUqVP1eVoAAAAA4OD28LVixQolJSVp1qxZ2rp1q3r27KnY2FgdOXKk2v6rVq1SQUGBY9uxY4e8vLw0atSoKn3fe+89bdq0SZGRkVX2jRkzRt98842ysrL00Ucf6R//+IcefPDBej8/AAAAAJAugfA1f/58TZgwQQkJCerWrZvS09PVtGlTvfnmm9X2Dw4OVkREhGPLyspS06ZNq4SvQ4cOafLkyVq6dKmaNGnitG/nzp3KzMzUG2+8oejoaN1www166aWXtHz5ch0+fLjBzhUAAADA5cut4auiokJbtmxRTEyMo81qtSomJkY5OTm1miMjI0OjR49WQECAo81ut+vee+/V9OnTdfXVV1cZk5OTo2bNmqlPnz6OtpiYGFmtVm3evLna45SXl6u0tNRpAwAAAIDacmv4Onr0qCorKxUeHu7UHh4ersLCwguOz83N1Y4dO/TAAw84tc+bN0/e3t6aMmVKteMKCwsVFhbm1Obt7a3g4OAaj5uamqqgoCDHFhUVdcH6AAAAAOAct992eDEyMjLUvXt39evXz9G2ZcsWvfjii1q8eLEsFku9HSs5OVklJSWO7cCBA/U2NwAAAADP59bwFRoaKi8vLxUVFTm1FxUVKSIi4rxjy8rKtHz5ciUmJjq1f/755zpy5Ihat24tb29veXt769///rceffRRtW3bVpIUERFRZUGPs2fP6vjx4zUe19fXVzabzWkDAAAAgNpya/jy8fFR7969lZ2d7Wiz2+3Kzs5W//79zzt25cqVKi8v19ixY53a7733Xm3fvl3btm1zbJGRkZo+fbo+/fRTSVL//v114sQJbdmyxTFu7dq1stvtio6OrsczBAAAAICfebu7gKSkJI0fP159+vRRv379lJaWprKyMiUkJEiSxo0bp1atWik1NdVpXEZGhoYPH66QkBCn9pCQkCptTZo0UUREhDp37ixJ6tq1q+Li4jRhwgSlp6frzJkzmjRpkkaPHl3tsvQAAAAAcLHcHr7i4+NVXFyslJQUFRYWqlevXsrMzHQswpGfny+r1fkCXV5enjZs2KDVq1fX+bhLly7VpEmTNGTIEFmtVt15551asGDBRZ0LAAAAANTEYhiG4e4iGqPS0lIFBQWppKSE578AAACAy1hts0GjXu0QAAAAABoLwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmuCTC18KFC9W2bVv5+fkpOjpaubm5NfYdNGiQLBZLlW3o0KGOPrNnz1aXLl0UEBCg5s2bKyYmRps3b3aap23btlXmmDt3boOdIwAAAIDLm9vD14oVK5SUlKRZs2Zp69at6tmzp2JjY3XkyJFq+69atUoFBQWObceOHfLy8tKoUaMcfTp16qSXX35ZX3/9tTZs2KC2bdvq5ptvVnFxsdNcTz31lNNckydPbtBzBQAAAHD5shiGYbizgOjoaPXt21cvv/yyJMlutysqKkqTJ0/WjBkzLjg+LS1NKSkpKigoUEBAQLV9SktLFRQUpDVr1mjIkCGSfr7yNXXqVE2dOrVOdZ+bs6SkRDabrU5zAAAAAGj8apsN3Hrlq6KiQlu2bFFMTIyjzWq1KiYmRjk5ObWaIyMjQ6NHj64xeFVUVOi1115TUFCQevbs6bRv7ty5CgkJ0bXXXqtnn31WZ8+erfvJAAAAAMB5eLvz4EePHlVlZaXCw8Od2sPDw7Vr164Ljs/NzdWOHTuUkZFRZd9HH32k0aNH6/Tp02rZsqWysrIUGhrq2D9lyhRdd911Cg4O1saNG5WcnKyCggLNnz+/2mOVl5ervLzc8bm0tLS2pwkAAAAA7g1fFysjI0Pdu3dXv379quwbPHiwtm3bpqNHj+r111/XXXfdpc2bNyssLEySlJSU5Ojbo0cP+fj46KGHHlJqaqp8fX2rzJeamqo5c+Y03MkAAAAA8Ghuve0wNDRUXl5eKioqcmovKipSRETEeceWlZVp+fLlSkxMrHZ/QECAOnTooOuvv14ZGRny9vau9grZOdHR0Tp79qz2799f7f7k5GSVlJQ4tgMHDpz/5AAAAADgF9wavnx8fNS7d29lZ2c72ux2u7Kzs9W/f//zjl25cqXKy8s1duzYWh3Lbrc73Tb437Zt2yar1eq4MvbffH19ZbPZnDYAAAAAqC2333aYlJSk8ePHq0+fPurXr5/S0tJUVlamhIQESdK4cePUqlUrpaamOo3LyMjQ8OHDFRIS4tReVlamP/7xj7r99tvVsmVLHT16VAsXLtShQ4ccy9Hn5ORo8+bNGjx4sAIDA5WTk6Np06Zp7Nixat68uTknDgAAAOCy4vbwFR8fr+LiYqWkpKiwsFC9evVSZmamYxGO/Px8Wa3OF+jy8vK0YcMGrV69usp8Xl5e2rVrl5YsWaKjR48qJCREffv21eeff66rr75a0s9XsZYvX67Zs2ervLxc7dq107Rp05yeAwMAAACA+uT293w1VrznCwAAAIDUSN7zBQAAAACXC8IXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAAAahReyvtOC7N3V7luQvVsvZH1nckWuIXwBAAAAaBS8rBbNryaALcjerflZ38nLanFTZbXj7e4CAAAAAKA2pgzpKEma//+vcE0Z0tERvJJu6uTYf6kifAEAAABoNH4ZwF5eu0cVlfZGEbwkbjsEAAAA0MhMGdJRPl5WVVTa5eNlbRTBSyJ8AQAAAGhkFmTvdgSvikp7jYtwXGq47RAAAABAo/Hfz3id+yzpkr8CRvgCAAAA0ChUt7hGdYtwXKoIXwAAAAAahUq7Ue3iGuc+V9oNd5RVaxbDMC7tCi9RpaWlCgoKUklJiWw2m7vLAQAAAOAmtc0GLLgBAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAAACACQhfAAAAAGACwhcAAAAAmIDwBQAAAAAmIHwBAAAAgAkIXwAAAABgAsIXAAAAAJiA8AUAAAAAJvB2dwGNlWEYkqTS0lI3VwIAAADAnc5lgnMZoSaErzo6efKkJCkqKsrNlQAAAAC4FJw8eVJBQUE17rcYF4pnqJbdbtfhw4cVGBgoi8Xi1lpKS0sVFRWlAwcOyGazubUW/Iy/E+D8+B4BAFysS+lniWEYOnnypCIjI2W11vxkF1e+6shqterKK690dxlObDab2/+PB2f8nQDnx/cIAOBiXSo/S853xescFtwAAAAAABMQvgAAAADABIQvD+Dr66tZs2bJ19fX3aXg/+PvBDg/vkcAABerMf4sYcENAAAAADABV74AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAExC+LlH/+Mc/dNtttykyMlIWi0Xvv/++Y9+ZM2f0xBNPqHv37goICFBkZKTGjRunw4cPO83x3Xff6Y477lBoaKhsNptuuOEGrVu3zuQz8Qypqanq27evAgMDFRYWpuHDhysvL8+pz6BBg2SxWJy2hx9+uMpcixcvVo8ePeTn56ewsDBNnDjRrNMAGtTs2bOrfA906dLFsf+1117ToEGDZLPZZLFYdOLECafx+/fvV2Jiotq1ayd/f3+1b99es2bNUkVFhclnAgAwy/l+55UkwzCUkpKili1byt/fXzExMdq9e7djv6s/O/bs2aPAwEA1a9asAc+qZoSvS1RZWZl69uyphQsXVtl3+vRpbd26VTNnztTWrVu1atUq5eXl6fbbb3fqN2zYMJ09e1Zr167Vli1b1LNnTw0bNkyFhYVmnYbHWL9+vSZOnKhNmzYpKytLZ86c0c0336yysjKnfhMmTFBBQYFje+aZZ5z2z58/X08++aRmzJihb775RmvWrFFsbKyZpwI0qKuvvtrpe2DDhg2OfadPn1ZcXJz+8Ic/VDt2165dstvtevXVV/XNN9/ohRdeUHp6eo39AQCN3/l+55WkZ555RgsWLFB6ero2b96sgIAAxcbG6qeffpLk2s+OM2fO6O6779avf/3rBj2n8zJwyZNkvPfee+ftk5uba0gy/v3vfxuGYRjFxcWGJOMf//iHo09paakhycjKymrIci8LR44cMSQZ69evd7TdeOONxiOPPFLjmOPHjxv+/v7GmjVrTKgQMN+sWbOMnj17XrDfunXrDEnGDz/8cMG+zzzzjNGuXbuLLw4AcMn779957Xa7ERERYTz77LOOthMnThi+vr7GX/7ylxrnqelnx+OPP26MHTvWWLRokREUFFSfpdcaV748RElJiSwWi+MSakhIiDp37qy33npLZWVlOnv2rF599VWFhYWpd+/e7i3WA5SUlEiSgoODndqXLl2q0NBQXXPNNUpOTtbp06cd+7KysmS323Xo0CF17dpVV155pe666y4dOHDA1NqBhrR7925FRkbqqquu0pgxY5Sfn39R85WUlFT5PgMAXB6+//57FRYWKiYmxtEWFBSk6Oho5eTk1Diuup8da9eu1cqVK2u8wmYWb7ceHfXip59+0hNPPKG7775bNptNkmSxWLRmzRoNHz5cgYGBslqtCgsLU2Zmppo3b+7mihs3u92uqVOnasCAAbrmmmsc7ffcc4/atGmjyMhIbd++XU888YTy8vK0atUqSdK+fftkt9v1pz/9SS+++KKCgoL0P//zP7rpppu0fft2+fj4uOuUgHoRHR2txYsXq3PnziooKNCcOXP061//Wjt27FBgYKDL8+3Zs0cvvfSSnnvuuQaoFgBwqTv3qEx4eLhTe3h4eI2P0VT3s+PYsWO677779Oc//9nxu7K7EL4auTNnzuiuu+6SYRj6v//7P0e7YRiaOHGiwsLC9Pnnn8vf319vvPGGbrvtNn3xxRdq2bKlG6tu3CZOnKgdO3Y4PcsiSQ8++KDj6+7du6tly5YaMmSI9u7dq/bt28tut+vMmTNasGCBbr75ZknSX/7yF0VERGjdunU8+4VG75ZbbnF83aNHD0VHR6tNmzb661//qsTERJfmOnTokOLi4jRq1ChNmDChvksFAHigmn52TJgwQffcc48GDhzoxup+xm2Hjdi54PXvf/9bWVlZTkl+7dq1+uijj7R8+XINGDBA1113nV555RX5+/tryZIlbqy6cZs0aZI++ugjrVu3TldeeeV5+0ZHR0v6+V9gJDkCb7du3Rx9WrRoodDQ0Iu+NQu4FDVr1kydOnVyfA/U1uHDhzV48GD96le/0muvvdZA1QEALnURERGSpKKiIqf2oqIix75zzvezY+3atXruuefk7e0tb29vJSYmqqSkRN7e3nrzzTcb9iT+C+GrkToXvHbv3q01a9YoJCTEaf+5Z42sVue/YqvVKrvdblqdnsIwDE2aNEnvvfee1q5dq3bt2l1wzLZt2yT9J3QNGDBAkpyWqD9+/LiOHj2qNm3a1H/RgJudOnVKe/fudelK+6FDhzRo0CD17t1bixYtqvLfMADA5aNdu3aKiIhQdna2o620tFSbN29W//79HW0X+tmRk5Ojbdu2ObannnpKgYGB2rZtm0aMGGHa+UjcdnjJOnXqlNO/Fn///ffatm2bgoOD1bJlS/32t7/V1q1b9dFHH6mystJx32twcLB8fHzUv39/NW/eXOPHj1dKSor8/f31+uuv6/vvv9fQoUPddVqN1sSJE7Vs2TJ98MEHCgwMdPx5BwUFyd/fX3v37tWyZct06623KiQkRNu3b9e0adM0cOBA9ejRQ5LUqVMn3XHHHXrkkUf02muvyWazKTk5WV26dNHgwYPdeXpAvXjsscd02223qU2bNjp8+LBmzZolLy8v3X333ZJ+vne/sLDQ8d+2r7/+WoGBgWrdurWCg4MdPzzbtGmj5557TsXFxY65//tfOAEAnuF8v/O2bt1aU6dO1f/+7/+qY8eOateunWbOnKnIyEgNHz5ckmr1s6Nr165Ox/zyyy9ltVqdnt03jVvWWMQFnVuK+b+38ePHG99//321+yQZ69atc8zxxRdfGDfffLMRHBxsBAYGGtdff73x97//3X0n1YjV9Oe9aNEiwzAMIz8/3xg4cKARHBxs+Pr6Gh06dDCmT59ulJSUOM1TUlJi3H///UazZs2M4OBgY8SIEUZ+fr4bzgiof/Hx8UbLli0NHx8fo1WrVkZ8fLyxZ88ex/5Zs2ad9/to0aJFNX6vAQA80/l+5zWMn5ebnzlzphEeHm74+voaQ4YMMfLy8hzj6/Kzw51LzVsMwzAaMNsBAAAAAMQzXwAAAABgCsIXAAAAAJiA8AUAAAAAJiB8AQAAAIAJCF8AAAAAYALCFwAAAACYgPAFAAAAACYgfAEAGqVBgwZp6tSpph93//79slgs2rZtW73N2bZtW6WlpdXbfACAS5O3uwsAAMBdPvvsMw0ePFg//PCDmjVr5rY6vvjiCwUEBLjt+AAAcxC+AABwsxYtWri7BACACbjtEADQaJ09e1aTJk1SUFCQQkNDNXPmTBmG4dj/9ttvq0+fPgoMDFRERITuueceHTlyRNLPtw8OHjxYktS8eXNZLBbdd999kiS73a5nnnlGHTp0kK+vr1q3bq0//vGPTsfet2+fBg8erKZNm6pnz57KycmpsU7DMDR79my1bt1avr6+ioyM1JQpUxz7f3nb4eLFi2WxWKpss2fPdvR/44031LVrV/n5+alLly565ZVXLuaPEQBgEsIXAKDRWrJkiby9vZWbm6sXX3xR8+fP1xtvvOHYf+bMGT399NP617/+pffff1/79+93BKyoqCi9++67kqS8vDwVFBToxRdflCQlJydr7ty5mjlzpr799lstW7ZM4eHhTsd+8skn9dhjj2nbtm3q1KmT7r77bp09e7baOt9991298MILevXVV7V79269//776t69e7V94+PjVVBQ4Nj+8pe/yNvbWwMGDJAkLV26VCkpKfrjH/+onTt36k9/+pNmzpypJUuWXNSfJQDABAYAAI3QjTfeaHTt2tWw2+2OtieeeMLo2rVrjWO++OILQ5Jx8uRJwzAMY926dYYk44cffnD0KS0tNXx9fY3XX3+92jm+//57Q5LxxhtvONq++eYbQ5Kxc+fOasc8//zzRqdOnYyKiopq97dp08Z44YUXqrTv2bPHCA4ONp555hlHW/v27Y1ly5Y59Xv66aeN/v37Vzs3AODSwZUvAECjdf3118tisTg+9+/fX7t371ZlZaUkacuWLbrtttvUunVrBQYG6sYbb5Qk5efn1zjnzp07VV5eriFDhpz32D169HB83bJlS0ly3NL430aNGqUff/xRV111lSZMmKD33nuvxqtk55SUlGjYsGEaOnSopk+fLkkqKyvT3r17lZiYqCuuuMKx/e///q/27t173vkAAO7HghsAAI9UVlam2NhYxcbGaunSpWrRooXy8/MVGxurioqKGsf5+/vXav4mTZo4vj4XAO12e7V9o6KilJeXpzVr1igrK0u///3v9eyzz2r9+vVO85xTWVmp+Ph42Ww2vfbaa472U6dOSZJef/11RUdHO43x8vKqVd0AAPchfAEAGq3Nmzc7fd60aZM6duwoLy8v7dq1S8eOHdPcuXMVFRUlSfryyy+d+vv4+EiS40qZJHXs2FH+/v7Kzs7WAw88UG+1+vv767bbbtNtt92miRMnqkuXLvr666913XXXVek7bdo0ff311/ryyy/l5+fnaA8PD1dkZKT27dunMWPG1FttAABzEL4AAI1Wfn6+kpKS9NBDD2nr1q166aWX9Pzzz0uSWrduLR8fH7300kt6+OGHtWPHDj399NNO49u0aSOLxaKPPvpIt956q/z9/XXFFVfoiSee0OOPPy4fHx8NGDBAxcXF+uabb5SYmFinOhcvXqzKykpFR0eradOm+vOf/yx/f3+1adOmSt9FixbplVde0XvvvSeLxaLCwkJJctxiOGfOHE2ZMkVBQUGKi4tTeXm5vvzyS/3www9KSkqqU30AAHPwzBcAoNEaN26cfvzxR/Xr108TJ07UI488ogcffFDSz+/OWrx4sVauXKlu3bpp7ty5eu6555zGt2rVSnPmzNGMGTMUHh6uSZMmSZJmzpypRx99VCkpKeratavi4+NrfJ6rNpo1a6bXX39dAwYMUI8ePbRmzRp9+OGHCgkJqdJ3/fr1qqys1O23366WLVs6tnO1P/DAA3rjjTe0aNEide/eXTfeeKMWL16sdu3a1bk+AIA5LIbxixeiAAAAAAAaBFe+AAAAAMAEhC8AAAAAMAHhCwAAAABMQPgCAAAAABMQvgAAAADABIQvAAAAADAB4QsAAAAATED4AgAAAAATEL4AAAAAwASELwAAAAAwAeELAAAAAExA+AIAAAAAE/w/inbExaYNQGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(batch_sizes)\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('cross-validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.235413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.192864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.162481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.130829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         0.235413\n",
       "1         256         0.192864\n",
       "2         512         0.162481\n",
       "3        1024         0.130829"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time':cross_validation_times})\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 128\n",
    "reason = \"The mean cross validation accuracy is the highest for batch size 128. Even though the time taken for the last epoch for batch size 128 is the longest, the time saved for other batch size is too small to be significant. Hence 128 is the optimal batch size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
