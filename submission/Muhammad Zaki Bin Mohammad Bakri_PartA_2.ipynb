{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>melspectrogram_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11631</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>2446</td>\n",
       "      <td>174.714286</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.455908</td>\n",
       "      <td>0.086070</td>\n",
       "      <td>0.255325</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.770311</td>\n",
       "      <td>101.961494</td>\n",
       "      <td>0.726778</td>\n",
       "      <td>65.895195</td>\n",
       "      <td>-0.372497</td>\n",
       "      <td>59.756054</td>\n",
       "      <td>-2.990087</td>\n",
       "      <td>48.541611</td>\n",
       "      <td>-2.369126</td>\n",
       "      <td>74.494980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>117.453835</td>\n",
       "      <td>1919</td>\n",
       "      <td>147.615385</td>\n",
       "      <td>0.570992</td>\n",
       "      <td>0.068214</td>\n",
       "      <td>0.533140</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.420724</td>\n",
       "      <td>72.575821</td>\n",
       "      <td>0.157023</td>\n",
       "      <td>89.650146</td>\n",
       "      <td>-3.008414</td>\n",
       "      <td>66.569794</td>\n",
       "      <td>-0.562329</td>\n",
       "      <td>61.818340</td>\n",
       "      <td>3.631580</td>\n",
       "      <td>86.445297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>3866</td>\n",
       "      <td>193.300000</td>\n",
       "      <td>0.665871</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.575811</td>\n",
       "      <td>0.055166</td>\n",
       "      <td>0.274959</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.171105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276058</td>\n",
       "      <td>79.474617</td>\n",
       "      <td>2.507980</td>\n",
       "      <td>64.289543</td>\n",
       "      <td>2.488033</td>\n",
       "      <td>57.481800</td>\n",
       "      <td>0.371860</td>\n",
       "      <td>56.641167</td>\n",
       "      <td>0.653117</td>\n",
       "      <td>58.880585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>184</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.581547</td>\n",
       "      <td>0.076387</td>\n",
       "      <td>0.457474</td>\n",
       "      <td>0.070914</td>\n",
       "      <td>0.260429</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.115304</td>\n",
       "      <td>87.528542</td>\n",
       "      <td>-4.961778</td>\n",
       "      <td>104.891090</td>\n",
       "      <td>4.375006</td>\n",
       "      <td>73.968193</td>\n",
       "      <td>0.428776</td>\n",
       "      <td>61.100105</td>\n",
       "      <td>-1.731462</td>\n",
       "      <td>44.836227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>71.777344</td>\n",
       "      <td>261</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>0.554061</td>\n",
       "      <td>0.081497</td>\n",
       "      <td>0.491283</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>0.261753</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.038899</td>\n",
       "      <td>53.558556</td>\n",
       "      <td>-2.577223</td>\n",
       "      <td>57.261269</td>\n",
       "      <td>-3.824014</td>\n",
       "      <td>46.565659</td>\n",
       "      <td>-6.141013</td>\n",
       "      <td>50.087326</td>\n",
       "      <td>-1.887392</td>\n",
       "      <td>59.745602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>143.554688</td>\n",
       "      <td>901</td>\n",
       "      <td>90.100000</td>\n",
       "      <td>0.478259</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>0.259968</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.065788</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.744453</td>\n",
       "      <td>77.242554</td>\n",
       "      <td>-5.778560</td>\n",
       "      <td>78.063904</td>\n",
       "      <td>-3.756855</td>\n",
       "      <td>57.650112</td>\n",
       "      <td>-6.038925</td>\n",
       "      <td>56.642426</td>\n",
       "      <td>-6.883427</td>\n",
       "      <td>68.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>11359</td>\n",
       "      <td>366.419355</td>\n",
       "      <td>0.528170</td>\n",
       "      <td>0.089229</td>\n",
       "      <td>0.514248</td>\n",
       "      <td>0.072142</td>\n",
       "      <td>0.270735</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.639221</td>\n",
       "      <td>85.417351</td>\n",
       "      <td>1.240076</td>\n",
       "      <td>63.720001</td>\n",
       "      <td>2.164308</td>\n",
       "      <td>57.301521</td>\n",
       "      <td>-5.378757</td>\n",
       "      <td>62.188622</td>\n",
       "      <td>3.131972</td>\n",
       "      <td>60.999619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>455</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>0.564319</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>0.384832</td>\n",
       "      <td>0.061052</td>\n",
       "      <td>0.249539</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.354200</td>\n",
       "      <td>46.093472</td>\n",
       "      <td>2.588070</td>\n",
       "      <td>63.986980</td>\n",
       "      <td>4.225698</td>\n",
       "      <td>56.400631</td>\n",
       "      <td>-0.810466</td>\n",
       "      <td>73.712036</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>76.151619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>4591</td>\n",
       "      <td>241.631579</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>0.531015</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.259324</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.262617</td>\n",
       "      <td>65.467903</td>\n",
       "      <td>-0.299933</td>\n",
       "      <td>61.815067</td>\n",
       "      <td>8.531980</td>\n",
       "      <td>61.917839</td>\n",
       "      <td>-0.106459</td>\n",
       "      <td>49.114147</td>\n",
       "      <td>3.769001</td>\n",
       "      <td>52.739552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>12925</td>\n",
       "      <td>430.833333</td>\n",
       "      <td>0.594553</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.486236</td>\n",
       "      <td>0.077371</td>\n",
       "      <td>0.259038</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.922426</td>\n",
       "      <td>73.793884</td>\n",
       "      <td>0.411759</td>\n",
       "      <td>80.801476</td>\n",
       "      <td>1.002124</td>\n",
       "      <td>61.276863</td>\n",
       "      <td>-5.808470</td>\n",
       "      <td>62.970455</td>\n",
       "      <td>-3.253069</td>\n",
       "      <td>54.050190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8439 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
       "11631  107.666016         2446     174.714286          0.581436   \n",
       "6619   117.453835         1919     147.615385          0.570992   \n",
       "1257   135.999178         3866     193.300000          0.665871   \n",
       "7611   103.359375          184      46.000000          0.581547   \n",
       "4665    71.777344          261      65.250000          0.554061   \n",
       "...           ...          ...            ...               ...   \n",
       "4859   143.554688          901      90.100000          0.478259   \n",
       "3264   107.666016        11359     366.419355          0.528170   \n",
       "9845   103.359375          455      75.833333          0.564319   \n",
       "10799  103.359375         4591     241.631579          0.721832   \n",
       "2732   135.999178        12925     430.833333          0.594553   \n",
       "\n",
       "       chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
       "11631         0.070376        0.455908       0.086070          0.255325   \n",
       "6619          0.068214        0.533140       0.067908          0.270572   \n",
       "1257          0.064646        0.575811       0.055166          0.274959   \n",
       "7611          0.076387        0.457474       0.070914          0.260429   \n",
       "4665          0.081497        0.491283       0.079467          0.261753   \n",
       "...                ...             ...            ...               ...   \n",
       "4859          0.096148        0.438220       0.092903          0.259968   \n",
       "3264          0.089229        0.514248       0.072142          0.270735   \n",
       "9845          0.094585        0.384832       0.061052          0.249539   \n",
       "10799         0.041792        0.531015       0.067686          0.259324   \n",
       "2732          0.074410        0.486236       0.077371          0.259038   \n",
       "\n",
       "       chroma_cens_var  melspectrogram_mean  ...  mfcc15_mean  mfcc15_var  \\\n",
       "11631         0.018142             0.024780  ...    -5.770311  101.961494   \n",
       "6619          0.010124             0.023933  ...    -2.420724   72.575821   \n",
       "1257          0.007731             0.171105  ...    -0.276058   79.474617   \n",
       "7611          0.015510             0.116615  ...    -3.115304   87.528542   \n",
       "4665          0.014819             0.009013  ...    -7.038899   53.558556   \n",
       "...                ...                  ...  ...          ...         ...   \n",
       "4859          0.015750             0.065788  ...   -10.744453   77.242554   \n",
       "3264          0.010036             0.002701  ...   -10.639221   85.417351   \n",
       "9845          0.021064             0.015486  ...    -1.354200   46.093472   \n",
       "10799         0.016084             0.031883  ...    -4.262617   65.467903   \n",
       "2732          0.016232             0.017917  ...    -5.922426   73.793884   \n",
       "\n",
       "       mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  \\\n",
       "11631     0.726778   65.895195    -0.372497   59.756054    -2.990087   \n",
       "6619      0.157023   89.650146    -3.008414   66.569794    -0.562329   \n",
       "1257      2.507980   64.289543     2.488033   57.481800     0.371860   \n",
       "7611     -4.961778  104.891090     4.375006   73.968193     0.428776   \n",
       "4665     -2.577223   57.261269    -3.824014   46.565659    -6.141013   \n",
       "...            ...         ...          ...         ...          ...   \n",
       "4859     -5.778560   78.063904    -3.756855   57.650112    -6.038925   \n",
       "3264      1.240076   63.720001     2.164308   57.301521    -5.378757   \n",
       "9845      2.588070   63.986980     4.225698   56.400631    -0.810466   \n",
       "10799    -0.299933   61.815067     8.531980   61.917839    -0.106459   \n",
       "2732      0.411759   80.801476     1.002124   61.276863    -5.808470   \n",
       "\n",
       "       mfcc18_var  mfcc19_mean  mfcc19_var  \n",
       "11631   48.541611    -2.369126   74.494980  \n",
       "6619    61.818340     3.631580   86.445297  \n",
       "1257    56.641167     0.653117   58.880585  \n",
       "7611    61.100105    -1.731462   44.836227  \n",
       "4665    50.087326    -1.887392   59.745602  \n",
       "...           ...          ...         ...  \n",
       "4859    56.642426    -6.883427   68.010582  \n",
       "3264    62.188622     3.131972   60.999619  \n",
       "9845    73.712036     0.072680   76.151619  \n",
       "10799   49.114147     3.769001   52.739552  \n",
       "2732    62.970455    -3.253069   54.050190  \n",
       "\n",
       "[8439 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP\n",
    "from common_utils import CustomDataset\n",
    "from common_utils import loss_fn\n",
    "from common_utils import split_dataset, preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, ['filename', 'label'], 0.3, 0)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = {}, {}, {}, {}\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "        for train_idx, test_idx in cv.split(X_train, y_train):\n",
    "            x_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            \n",
    "            x_test_fold, y_test_fold = X_train[test_idx], y_train[test_idx]\n",
    "\n",
    "            x_train_fold_scale, x_test_fold_scale = preprocess_dataset(x_train_fold, x_test_fold)\n",
    "            \n",
    "            X_train_scaled_dict[batch_size].append(x_train_fold_scale)\n",
    "            X_val_scaled_dict[batch_size].append(x_test_fold_scale)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_test_fold)\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Size: 128\n",
      "Done!\n",
      "fold 0:0.6498815165876777\n",
      "Done!\n",
      "fold 1:0.7328199052132701\n",
      "Done!\n",
      "fold 2:0.7565165876777251\n",
      "Done!\n",
      "fold 3:0.7855450236966824\n",
      "Done!\n",
      "fold 4:0.8037937166567872\n",
      "\n",
      "Batch Size: 256\n",
      "Done!\n",
      "fold 0:0.6700236966824644\n",
      "Done!\n",
      "fold 1:0.7340047393364929\n",
      "Done!\n",
      "fold 2:0.7618483412322274\n",
      "Done!\n",
      "fold 3:0.7535545023696683\n",
      "Done!\n",
      "fold 4:0.7860106698280972\n",
      "\n",
      "Batch Size: 512\n",
      "Done!\n",
      "fold 0:0.6368483412322274\n",
      "Done!\n",
      "fold 1:0.6806872037914692\n",
      "Done!\n",
      "fold 2:0.7014218009478673\n",
      "Done!\n",
      "fold 3:0.7233412322274881\n",
      "Done!\n",
      "fold 4:0.7747480735032602\n",
      "\n",
      "Batch Size: 1024\n",
      "Done!\n",
      "fold 0:0.658175355450237\n",
      "Done!\n",
      "fold 1:0.7239336492890995\n",
      "Done!\n",
      "fold 2:0.7422985781990521\n",
      "Done!\n",
      "fold 3:0.7701421800947867\n",
      "Done!\n",
      "fold 4:0.7711914641375223\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from datetime import datetime\n",
    "no_epochs = 100\n",
    "from common_utils import EarlyStopper\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter):\n",
    "    cross_validation_accuracies, cross_validation_times = [], []\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "    for batch_size in batch_sizes:\n",
    "        print()\n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        \n",
    "        model = MLP(77,128,2)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        fold_acc = []\n",
    "        fold_time = []\n",
    "        for fold in range(5):\n",
    "            train_data = CustomDataset(X_train_scaled_dict[batch_size][fold], y_train_dict[batch_size][fold])\n",
    "            test_data = CustomDataset(X_val_scaled_dict[batch_size][fold], y_val_dict[batch_size][fold])\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "            epoch_acc = []\n",
    "            for epoch in range(no_epochs):\n",
    "                acc = 0\n",
    "                start_time = datetime.now()\n",
    "                for batch, (x_train,y_train) in enumerate(train_dataloader):\n",
    "                    pred = model(x_train)\n",
    "                    loss = loss_fn(pred, y_train)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                \n",
    "                size = len(test_dataloader.dataset)\n",
    "                correct = 0\n",
    "                test_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch,(x_test, y_test) in enumerate(test_dataloader):\n",
    "                        pred = model(x_test)\n",
    "                        test_loss += loss_fn(pred,y_test).item()\n",
    "                        correct += (pred.argmax(1) == y_test).type(torch.float).sum().item()\n",
    "                        \n",
    "                acc = correct/size\n",
    "\n",
    "                test_loss /= size\n",
    "                end_time = datetime.now()\n",
    "                elapsed_time = end_time - start_time\n",
    "                if early_stopper.early_stop(test_loss):\n",
    "                    print(\"Done!\")\n",
    "                    fold_time.append(elapsed_time.microseconds/1000000)\n",
    "                    fold_acc.append(acc)\n",
    "\n",
    "                    break\n",
    "                if epoch == no_epochs-1:\n",
    "                    fold_time.append(elapsed_time.microseconds/1000000)\n",
    "                    fold_acc.append(acc)\n",
    "\n",
    "            print(\"fold \" + str(fold) + \":\" + str(acc))\n",
    "        cross_validation_accuracies.append(np.mean(np.array(fold_acc), axis = 0))\n",
    "        cross_validation_times.append(np.mean(np.array(fold_time), axis = 0))\n",
    "\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "        \n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cross-validation accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(batch_sizes)\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('cross-validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.159309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.119217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.113322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.095732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         0.159309\n",
       "1         256         0.119217\n",
       "2         512         0.113322\n",
       "3        1024         0.095732"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time':cross_validation_times})\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 128\n",
    "reason = \"The mean cross validation accuracy is the highest for batch size 128. Even though the time taken for the last epoch for batch size 128 is the longest, the time saved for other batch size is too small to be significant. Hence 128 is the optimal batch size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
