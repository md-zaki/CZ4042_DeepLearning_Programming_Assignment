{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c5cb62ac-8e88-43e6-bce9-da20fabf38ff",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c7e82aadc4d77a8b23f7f880449f9e3",
     "grade": false,
     "grade_id": "a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "26b4ac2a-d56e-4151-8e0a-4a833cbc643e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb28aa752ce5540f5b18d10694b52ea9",
     "grade": false,
     "grade_id": "a22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation.\n",
    "\n",
    "* note: some cells are non-editable and cannot be filled, but leave them untouched. Fill up only cells which are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fb9411ad-2324-400e-852e-ff5c0ca716f0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aceec82011f43733c0551ca196f1b16c",
     "grade": false,
     "grade_id": "a2_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {128, 256, 512, 1024}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0edc610-21e6-4cc7-9603-59318b961990",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b0edc610-21e6-4cc7-9603-59318b961990",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "909acb3c7ff3883eb5381eb586615d3b",
     "grade": false,
     "grade_id": "libraries",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e12861-4713-4914-9f4b-8a7381708243",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e8e12861-4713-4914-9f4b-8a7381708243",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed97d9f30da032a5e349047c614efec1",
     "grade": false,
     "grade_id": "a2_1_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2. To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "\n",
    "in a separate file called **common_utils.py**\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a1a982-de85-46de-b890-3b81f79f5887",
   "metadata": {
    "deletable": false,
    "id": "37a1a982-de85-46de-b890-3b81f79f5887",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db3ca972642b1447dba3ebd5f2db24b",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tempo</th>\n",
       "      <th>total_beats</th>\n",
       "      <th>average_beats</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>chroma_cq_mean</th>\n",
       "      <th>chroma_cq_var</th>\n",
       "      <th>chroma_cens_mean</th>\n",
       "      <th>chroma_cens_var</th>\n",
       "      <th>melspectrogram_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15_mean</th>\n",
       "      <th>mfcc15_var</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11631</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>2446</td>\n",
       "      <td>174.714286</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.455908</td>\n",
       "      <td>0.086070</td>\n",
       "      <td>0.255325</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.770311</td>\n",
       "      <td>101.961494</td>\n",
       "      <td>0.726778</td>\n",
       "      <td>65.895195</td>\n",
       "      <td>-0.372497</td>\n",
       "      <td>59.756054</td>\n",
       "      <td>-2.990087</td>\n",
       "      <td>48.541611</td>\n",
       "      <td>-2.369126</td>\n",
       "      <td>74.494980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>117.453835</td>\n",
       "      <td>1919</td>\n",
       "      <td>147.615385</td>\n",
       "      <td>0.570992</td>\n",
       "      <td>0.068214</td>\n",
       "      <td>0.533140</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.023933</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.420724</td>\n",
       "      <td>72.575821</td>\n",
       "      <td>0.157023</td>\n",
       "      <td>89.650146</td>\n",
       "      <td>-3.008414</td>\n",
       "      <td>66.569794</td>\n",
       "      <td>-0.562329</td>\n",
       "      <td>61.818340</td>\n",
       "      <td>3.631580</td>\n",
       "      <td>86.445297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>3866</td>\n",
       "      <td>193.300000</td>\n",
       "      <td>0.665871</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.575811</td>\n",
       "      <td>0.055166</td>\n",
       "      <td>0.274959</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>0.171105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276058</td>\n",
       "      <td>79.474617</td>\n",
       "      <td>2.507980</td>\n",
       "      <td>64.289543</td>\n",
       "      <td>2.488033</td>\n",
       "      <td>57.481800</td>\n",
       "      <td>0.371860</td>\n",
       "      <td>56.641167</td>\n",
       "      <td>0.653117</td>\n",
       "      <td>58.880585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>184</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.581547</td>\n",
       "      <td>0.076387</td>\n",
       "      <td>0.457474</td>\n",
       "      <td>0.070914</td>\n",
       "      <td>0.260429</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.115304</td>\n",
       "      <td>87.528542</td>\n",
       "      <td>-4.961778</td>\n",
       "      <td>104.891090</td>\n",
       "      <td>4.375006</td>\n",
       "      <td>73.968193</td>\n",
       "      <td>0.428776</td>\n",
       "      <td>61.100105</td>\n",
       "      <td>-1.731462</td>\n",
       "      <td>44.836227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>71.777344</td>\n",
       "      <td>261</td>\n",
       "      <td>65.250000</td>\n",
       "      <td>0.554061</td>\n",
       "      <td>0.081497</td>\n",
       "      <td>0.491283</td>\n",
       "      <td>0.079467</td>\n",
       "      <td>0.261753</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.038899</td>\n",
       "      <td>53.558556</td>\n",
       "      <td>-2.577223</td>\n",
       "      <td>57.261269</td>\n",
       "      <td>-3.824014</td>\n",
       "      <td>46.565659</td>\n",
       "      <td>-6.141013</td>\n",
       "      <td>50.087326</td>\n",
       "      <td>-1.887392</td>\n",
       "      <td>59.745602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>143.554688</td>\n",
       "      <td>901</td>\n",
       "      <td>90.100000</td>\n",
       "      <td>0.478259</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>0.259968</td>\n",
       "      <td>0.015750</td>\n",
       "      <td>0.065788</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.744453</td>\n",
       "      <td>77.242554</td>\n",
       "      <td>-5.778560</td>\n",
       "      <td>78.063904</td>\n",
       "      <td>-3.756855</td>\n",
       "      <td>57.650112</td>\n",
       "      <td>-6.038925</td>\n",
       "      <td>56.642426</td>\n",
       "      <td>-6.883427</td>\n",
       "      <td>68.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>107.666016</td>\n",
       "      <td>11359</td>\n",
       "      <td>366.419355</td>\n",
       "      <td>0.528170</td>\n",
       "      <td>0.089229</td>\n",
       "      <td>0.514248</td>\n",
       "      <td>0.072142</td>\n",
       "      <td>0.270735</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.639221</td>\n",
       "      <td>85.417351</td>\n",
       "      <td>1.240076</td>\n",
       "      <td>63.720001</td>\n",
       "      <td>2.164308</td>\n",
       "      <td>57.301521</td>\n",
       "      <td>-5.378757</td>\n",
       "      <td>62.188622</td>\n",
       "      <td>3.131972</td>\n",
       "      <td>60.999619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>455</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>0.564319</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>0.384832</td>\n",
       "      <td>0.061052</td>\n",
       "      <td>0.249539</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.354200</td>\n",
       "      <td>46.093472</td>\n",
       "      <td>2.588070</td>\n",
       "      <td>63.986980</td>\n",
       "      <td>4.225698</td>\n",
       "      <td>56.400631</td>\n",
       "      <td>-0.810466</td>\n",
       "      <td>73.712036</td>\n",
       "      <td>0.072680</td>\n",
       "      <td>76.151619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799</th>\n",
       "      <td>103.359375</td>\n",
       "      <td>4591</td>\n",
       "      <td>241.631579</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.041792</td>\n",
       "      <td>0.531015</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.259324</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>0.031883</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.262617</td>\n",
       "      <td>65.467903</td>\n",
       "      <td>-0.299933</td>\n",
       "      <td>61.815067</td>\n",
       "      <td>8.531980</td>\n",
       "      <td>61.917839</td>\n",
       "      <td>-0.106459</td>\n",
       "      <td>49.114147</td>\n",
       "      <td>3.769001</td>\n",
       "      <td>52.739552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>135.999178</td>\n",
       "      <td>12925</td>\n",
       "      <td>430.833333</td>\n",
       "      <td>0.594553</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.486236</td>\n",
       "      <td>0.077371</td>\n",
       "      <td>0.259038</td>\n",
       "      <td>0.016232</td>\n",
       "      <td>0.017917</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.922426</td>\n",
       "      <td>73.793884</td>\n",
       "      <td>0.411759</td>\n",
       "      <td>80.801476</td>\n",
       "      <td>1.002124</td>\n",
       "      <td>61.276863</td>\n",
       "      <td>-5.808470</td>\n",
       "      <td>62.970455</td>\n",
       "      <td>-3.253069</td>\n",
       "      <td>54.050190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8439 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tempo  total_beats  average_beats  chroma_stft_mean  \\\n",
       "11631  107.666016         2446     174.714286          0.581436   \n",
       "6619   117.453835         1919     147.615385          0.570992   \n",
       "1257   135.999178         3866     193.300000          0.665871   \n",
       "7611   103.359375          184      46.000000          0.581547   \n",
       "4665    71.777344          261      65.250000          0.554061   \n",
       "...           ...          ...            ...               ...   \n",
       "4859   143.554688          901      90.100000          0.478259   \n",
       "3264   107.666016        11359     366.419355          0.528170   \n",
       "9845   103.359375          455      75.833333          0.564319   \n",
       "10799  103.359375         4591     241.631579          0.721832   \n",
       "2732   135.999178        12925     430.833333          0.594553   \n",
       "\n",
       "       chroma_stft_var  chroma_cq_mean  chroma_cq_var  chroma_cens_mean  \\\n",
       "11631         0.070376        0.455908       0.086070          0.255325   \n",
       "6619          0.068214        0.533140       0.067908          0.270572   \n",
       "1257          0.064646        0.575811       0.055166          0.274959   \n",
       "7611          0.076387        0.457474       0.070914          0.260429   \n",
       "4665          0.081497        0.491283       0.079467          0.261753   \n",
       "...                ...             ...            ...               ...   \n",
       "4859          0.096148        0.438220       0.092903          0.259968   \n",
       "3264          0.089229        0.514248       0.072142          0.270735   \n",
       "9845          0.094585        0.384832       0.061052          0.249539   \n",
       "10799         0.041792        0.531015       0.067686          0.259324   \n",
       "2732          0.074410        0.486236       0.077371          0.259038   \n",
       "\n",
       "       chroma_cens_var  melspectrogram_mean  ...  mfcc15_mean  mfcc15_var  \\\n",
       "11631         0.018142             0.024780  ...    -5.770311  101.961494   \n",
       "6619          0.010124             0.023933  ...    -2.420724   72.575821   \n",
       "1257          0.007731             0.171105  ...    -0.276058   79.474617   \n",
       "7611          0.015510             0.116615  ...    -3.115304   87.528542   \n",
       "4665          0.014819             0.009013  ...    -7.038899   53.558556   \n",
       "...                ...                  ...  ...          ...         ...   \n",
       "4859          0.015750             0.065788  ...   -10.744453   77.242554   \n",
       "3264          0.010036             0.002701  ...   -10.639221   85.417351   \n",
       "9845          0.021064             0.015486  ...    -1.354200   46.093472   \n",
       "10799         0.016084             0.031883  ...    -4.262617   65.467903   \n",
       "2732          0.016232             0.017917  ...    -5.922426   73.793884   \n",
       "\n",
       "       mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean  \\\n",
       "11631     0.726778   65.895195    -0.372497   59.756054    -2.990087   \n",
       "6619      0.157023   89.650146    -3.008414   66.569794    -0.562329   \n",
       "1257      2.507980   64.289543     2.488033   57.481800     0.371860   \n",
       "7611     -4.961778  104.891090     4.375006   73.968193     0.428776   \n",
       "4665     -2.577223   57.261269    -3.824014   46.565659    -6.141013   \n",
       "...            ...         ...          ...         ...          ...   \n",
       "4859     -5.778560   78.063904    -3.756855   57.650112    -6.038925   \n",
       "3264      1.240076   63.720001     2.164308   57.301521    -5.378757   \n",
       "9845      2.588070   63.986980     4.225698   56.400631    -0.810466   \n",
       "10799    -0.299933   61.815067     8.531980   61.917839    -0.106459   \n",
       "2732      0.411759   80.801476     1.002124   61.276863    -5.808470   \n",
       "\n",
       "       mfcc18_var  mfcc19_mean  mfcc19_var  \n",
       "11631   48.541611    -2.369126   74.494980  \n",
       "6619    61.818340     3.631580   86.445297  \n",
       "1257    56.641167     0.653117   58.880585  \n",
       "7611    61.100105    -1.731462   44.836227  \n",
       "4665    50.087326    -1.887392   59.745602  \n",
       "...           ...          ...         ...  \n",
       "4859    56.642426    -6.883427   68.010582  \n",
       "3264    62.188622     3.131972   60.999619  \n",
       "9845    73.712036     0.072680   76.151619  \n",
       "10799   49.114147     3.769001   52.739552  \n",
       "2732    62.970455    -3.253069   54.050190  \n",
       "\n",
       "[8439 rows x 77 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from common_utils import MLP\n",
    "from common_utils import CustomDataset\n",
    "from common_utils import loss_fn\n",
    "from common_utils import split_dataset, preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, ['filename', 'label'], 0.3, 0)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5aa562e7-23c3-4920-ae63-4563bf30e39d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae6b33318200b4bc38d431576963edb1",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82ea67d6-1eb4-428d-9407-9d988e927ff6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c738d3b4888de90dda8c532036bc5fe5",
     "grade": false,
     "grade_id": "a2_1_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3. Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
   "metadata": {
    "deletable": false,
    "id": "deab683a-2c9e-4e62-823a-e8b4a186bda8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d02dac62baa528c191eb4f47b2495406",
     "grade": false,
     "grade_id": "dataset",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = {}, {}, {}, {}\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_dict[batch_size] = []\n",
    "        X_val_scaled_dict[batch_size] = []\n",
    "        y_train_dict[batch_size] = []\n",
    "        y_val_dict[batch_size] = []\n",
    "        for train_idx, test_idx in cv.split(X_train, y_train):\n",
    "            x_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            \n",
    "            x_test_fold, y_test_fold = X_train[test_idx], y_train[test_idx]\n",
    "\n",
    "            x_train_fold_scale, x_test_fold_scale = preprocess_dataset(x_train_fold, x_test_fold)\n",
    "            \n",
    "            X_train_scaled_dict[batch_size].append(x_train_fold_scale)\n",
    "            X_val_scaled_dict[batch_size].append(x_test_fold_scale)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            y_val_dict[batch_size].append(y_test_fold)\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ca332-9676-42bd-9801-0f5f4157a777",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "235ca332-9676-42bd-9801-0f5f4157a777",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ae5f281cd84f4d36f81f2ae126cf915",
     "grade": true,
     "grade_id": "correct_dataset",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8df744af-f485-4871-9e0a-70fd41d1df4d",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dcf6be1ad49306172e6f27243e613f2",
     "grade": true,
     "grade_id": "correct_dataset2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "558aa470-6d7e-454c-9cda-9ad881d58c53",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064d68c9708b5e3f1e2463001b6d78b4",
     "grade": false,
     "grade_id": "a2_1_4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4. Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
   "metadata": {
    "deletable": false,
    "id": "3107ebe9-d121-4510-9782-2a62d32258d0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9665887943f38ae7bed6c1d8351903b",
     "grade": true,
     "grade_id": "hyperparameter_tuning",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Size: 128\n",
      "Done!\n",
      "fold 0:0.7251184834123223\n",
      "Done!\n",
      "fold 1:0.8696682464454977\n",
      "Done!\n",
      "fold 2:0.8933649289099526\n",
      "Done!\n",
      "fold 3:0.9075829383886256\n",
      "Done!\n",
      "fold 4:0.9110847658565501\n",
      "\n",
      "Batch Size: 256\n",
      "Done!\n",
      "fold 0:0.5639810426540285\n",
      "Done!\n",
      "fold 1:0.5746445497630331\n",
      "Done!\n",
      "fold 2:0.5983412322274881\n",
      "Done!\n",
      "fold 3:0.6161137440758294\n",
      "Done!\n",
      "fold 4:0.6520450503852994\n",
      "\n",
      "Batch Size: 512\n",
      "Done!\n",
      "fold 0:0.5699052132701422\n",
      "Done!\n",
      "fold 1:0.5710900473933649\n",
      "Done!\n",
      "fold 2:0.6984597156398105\n",
      "Done!\n",
      "fold 3:0.7991706161137441\n",
      "Done!\n",
      "fold 4:0.8245406046235921\n",
      "\n",
      "Batch Size: 1024\n",
      "Done!\n",
      "fold 0:0.7114928909952607\n",
      "Done!\n",
      "fold 1:0.8388625592417062\n",
      "Done!\n",
      "fold 2:0.8637440758293838\n",
      "Done!\n",
      "fold 3:0.8637440758293838\n",
      "Done!\n",
      "fold 4:0.8861885002963841\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from datetime import datetime\n",
    "no_epochs = 100\n",
    "from common_utils import EarlyStopper\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter):\n",
    "    cross_validation_accuracies, cross_validation_times = [], []\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "    for batch_size in batch_sizes:\n",
    "        print()\n",
    "        print(\"Batch Size: \" + str(batch_size))\n",
    "        \n",
    "        model = MLP(77,128,1)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        fold_acc = []\n",
    "        fold_time = []\n",
    "        for fold in range(5):\n",
    "            train_data = CustomDataset(X_train_scaled_dict[batch_size][fold], y_train_dict[batch_size][fold])\n",
    "            test_data = CustomDataset(X_val_scaled_dict[batch_size][fold], y_val_dict[batch_size][fold])\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "            epoch_acc = []\n",
    "            for epoch in range(no_epochs):\n",
    "                acc = 0\n",
    "                start_time = datetime.now()\n",
    "                model.train()\n",
    "                for batch, (x_train,y_train) in enumerate(train_dataloader):\n",
    "                    pred = model(x_train)\n",
    "                    pred = pred.flatten()\n",
    "                    loss = loss_fn(pred, y_train)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                \n",
    "                size = len(test_dataloader.dataset)\n",
    "                correct = 0\n",
    "                test_loss = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch,(x_test, y_test) in enumerate(test_dataloader):\n",
    "                        pred = model(x_test)\n",
    "                        pred = pred.flatten()\n",
    "                        test_loss += loss_fn(pred,y_test).item()\n",
    "                        correct += (pred.round() == y_test).type(torch.float).sum().item()\n",
    "                        \n",
    "                acc = correct/size\n",
    "\n",
    "                test_loss /= size\n",
    "                end_time = datetime.now()\n",
    "                elapsed_time = end_time - start_time\n",
    "                if early_stopper.early_stop(test_loss):\n",
    "                    print(\"Done!\")\n",
    "                    fold_time.append(elapsed_time.microseconds/1000000)\n",
    "                    fold_acc.append(acc)\n",
    "\n",
    "                    break\n",
    "                if epoch == no_epochs-1:\n",
    "                    fold_time.append(elapsed_time.microseconds/1000000)\n",
    "                    fold_acc.append(acc)\n",
    "\n",
    "            print(\"fold \" + str(fold) + \":\" + str(acc))\n",
    "        cross_validation_accuracies.append(np.mean(np.array(fold_acc), axis = 0))\n",
    "        cross_validation_times.append(np.mean(np.array(fold_time), axis = 0))\n",
    "\n",
    "    return cross_validation_accuracies, cross_validation_times\n",
    "        \n",
    "\n",
    "batch_sizes = [128, 256, 512, 1024]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64384c9c-ddd5-4460-bf37-b9977443a65c",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "975e552e751c4efb2cec0eac214f85cd",
     "grade": true,
     "grade_id": "correct_hyperparameter_tuning",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "b6756ab6-92e0-4a5e-b4b9-aebe009f5480",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69421943e22521de848bb03a50f57767",
     "grade": false,
     "grade_id": "a2_1_5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "5. Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
   "metadata": {
    "deletable": false,
    "id": "8fa3afdf-eed6-47b9-9acc-bc2304c46ec3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17599eb29fd6e3a1e2812f0ff7cba983",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cross-validation accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(batch_sizes, cross_validation_accuracies, marker = 'x', linestyle = 'None')\n",
    "plt.xticks(batch_sizes)\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('cross-validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "baab6e4d-4e8b-4358-a68d-682f60db4a06",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e8d298b5774c4044f1c3f950c46214",
     "grade": false,
     "grade_id": "a2_1_6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "6. Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
   "metadata": {
    "deletable": false,
    "id": "081aa567-cd92-4749-93fd-fc6608a1f6ae",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c18e30a9850c282ad725336848222a62",
     "grade": false,
     "grade_id": "times",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.149991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>0.123725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>0.117931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.099875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0         128         0.149991\n",
       "1         256         0.123725\n",
       "2         512         0.117931\n",
       "3        1024         0.099875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': batch_sizes,\n",
    "                   'Last Epoch Time':cross_validation_times})\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1c83d786-706b-46d2-9220-3b09e4c473b3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2fc4a52c2a0af7ea586ea85cec9b3e9",
     "grade": true,
     "grade_id": "correct_times",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
   "metadata": {
    "deletable": false,
    "id": "d46dfd1c-1d3c-46e4-98d6-21c2672ad31b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38690f32ec506325fc73c8353b77d041",
     "grade": false,
     "grade_id": "batch_size",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 128\n",
    "reason = \"The mean cross validation accuracy is the highest for batch size 128. Even though the time taken for the last epoch for batch size 128 is the longest, the time saved for other batch size is too small to be significant. Hence 128 is the optimal batch size.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "096ff7b5-6a77-47d4-941e-37bc495b6558",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f695b961ed43ec6a31b7647e078fd8d6",
     "grade": true,
     "grade_id": "correct_batch_size",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
